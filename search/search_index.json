{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"N\u00d8MADE","text":"<p>N\u00d8de MAnagement DEvice \u2014 Lightweight HPC monitoring, visualization, and predictive analytics.</p> <p>\"Travels light, adapts to its environment, and doesn't need permanent infrastructure.\"</p>"},{"location":"#what-is-nmade","title":"What is N\u00d8MADE?","text":"<p>N\u00d8MADE is a self-contained monitoring and prediction system for HPC clusters. Unlike heavyweight solutions requiring complex infrastructure, N\u00d8MADE deploys quickly, runs with minimal resources, and provides actionable insights through:</p> <ul> <li>Real-time monitoring of disk, CPU, memory, GPU, and SLURM jobs</li> <li>Predictive analytics using machine learning and similarity networks</li> <li>Educational analytics tracking computational proficiency development</li> <li>Multi-cluster dashboards with partition-level views</li> <li>Derivative analysis detecting accelerating trends before thresholds</li> </ul>"},{"location":"#philosophy","title":"Philosophy","text":"<p>Inspired by nomadic principles:</p> Principle Implementation Travels light SQLite database, minimal dependencies, no external services Adapts to environment Configurable collectors, flexible alerts, cluster-agnostic Leaves no trace Clean uninstall, no system modifications required"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code>pip install nomade-hpc\nnomade demo                    # Try with synthetic data\nnomade dashboard               # Open http://localhost:8050\n</code></pre> <p>For production deployment, see Installation.</p>"},{"location":"#features-at-a-glance","title":"Features at a Glance","text":"Feature Description Learn More Dashboard Multi-cluster real-time monitoring Dashboard Educational Analytics Track proficiency development Edu Module ML Prediction Job failure prediction ML Framework Network Analysis Similarity-based clustering Network Methodology Alerts Threshold + predictive alerts Alerts Community Export Anonymized cross-institutional data CLI Reference"},{"location":"ARCHITECTURE/","title":"N\u00d8MADE Architecture Summary","text":""},{"location":"ARCHITECTURE/#data-collection-overview","title":"Data Collection Overview","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         N\u00d8MADE Data Collection v0.2.0                        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                              \u2502\n\u2502  SYSTEM COLLECTORS (every 60s):                                              \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502 disk         \u2502 Filesystem usage (total, used, free, projections)       \u2502  \u2502\n\u2502  \u2502 iostat       \u2502 Device I/O: %iowait, utilization, latency               \u2502  \u2502\n\u2502  \u2502 mpstat       \u2502 Per-core CPU: utilization, imbalance detection          \u2502  \u2502\n\u2502  \u2502 vmstat       \u2502 Memory pressure, swap activity, blocked processes       \u2502  \u2502\n\u2502  \u2502 nfs          \u2502 NFS I/O: ops/sec, throughput, RTT, retransmissions      \u2502  \u2502\n\u2502  \u2502 gpu          \u2502 NVIDIA GPU: utilization, memory, temperature, power     \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                                                                              \u2502\n\u2502  SLURM COLLECTORS (every 60s):                                               \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502 slurm        \u2502 Queue state: pending, running, partition stats          \u2502  \u2502\n\u2502  \u2502 job_metrics  \u2502 sacct data: CPU/mem efficiency, health scores           \u2502  \u2502\n\u2502  \u2502 node_state   \u2502 Node allocation, drain reasons, CPU load, memory        \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                                                                              \u2502\n\u2502  JOB MONITOR (every 30s):                                                    \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502 job_monitor  \u2502 Per-job I/O: NFS vs local writes from /proc/[pid]/io    \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                                                                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"ARCHITECTURE/#feature-vector-19-dimensions","title":"Feature Vector (19 dimensions)","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Feature Vector for Similarity Analysis                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                             \u2502\n\u2502  FROM SACCT (job outcome):              FROM IOSTAT (system I/O):           \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502  1. health_score        [0-1]  \u2502     \u2502 11. avg_iowait_percent   [0-1] \u2502  \u2502\n\u2502  \u2502  2. cpu_efficiency      [0-1]  \u2502     \u2502 12. peak_iowait_percent  [0-1] \u2502  \u2502\n\u2502  \u2502  3. memory_efficiency   [0-1]  \u2502     \u2502 13. avg_device_util      [0-1] \u2502  \u2502\n\u2502  \u2502  4. used_gpu            [0,1]  \u2502     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502  \u2502  5. had_swap            [0,1]  \u2502                                         \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     FROM MPSTAT (CPU cores):            \u2502\n\u2502                                         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  FROM JOB_MONITOR (I/O behavior):       \u2502 14. avg_core_busy        [0-1] \u2502  \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u2502 15. core_imbalance_ratio [0-1] \u2502  \u2502\n\u2502  \u2502  6. total_write_gb      [0-1]  \u2502     \u2502 16. max_core_busy        [0-1] \u2502  \u2502\n\u2502  \u2502  7. write_rate_mbps     [0-1]  \u2502     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502  \u2502  8. nfs_ratio           [0-1]  \u2502                                         \u2502\n\u2502  \u2502  9. runtime_minutes     [0-1]  \u2502     FROM VMSTAT (memory pressure):      \u2502\n\u2502  \u2502 10. write_intensity     [0-1]  \u2502     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502 17. avg_memory_pressure  [0-1] \u2502  \u2502\n\u2502                                         \u2502 18. peak_swap_activity   [0-1] \u2502  \u2502\n\u2502                                         \u2502 19. avg_procs_blocked    [0-1] \u2502  \u2502\n\u2502                                         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                                                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"ARCHITECTURE/#collector-details","title":"Collector Details","text":"# Collector Source Key Data Graceful Skip 1 <code>disk</code> <code>shutil.disk_usage</code> total/used/free, fill rate projections No 2 <code>slurm</code> <code>squeue</code>, <code>sinfo</code> pending/running jobs, partition stats No 3 <code>job_metrics</code> <code>sacct</code> CPU/mem efficiency, exit codes, health No 4 <code>iostat</code> <code>iostat -x</code> %iowait, device util, r/w latency No 5 <code>mpstat</code> <code>mpstat -P ALL</code> per-core CPU, imbalance ratio No 6 <code>vmstat</code> <code>vmstat</code> swap, memory pressure, blocked procs No 7 <code>node_state</code> <code>scontrol show node</code> allocation, drain reasons, load No 8 <code>gpu</code> <code>nvidia-smi</code> util, memory, temp, power Yes (if no GPU) 9 <code>nfs</code> <code>nfsiostat</code> ops/sec, throughput, RTT Yes (if no NFS) 10 <code>job_monitor</code> <code>/proc/[pid]/io</code> per-job NFS vs local I/O No"},{"location":"ARCHITECTURE/#database-tables","title":"Database Tables","text":""},{"location":"ARCHITECTURE/#system-metrics","title":"System Metrics","text":"<ul> <li><code>filesystems</code> - disk usage snapshots</li> <li><code>iostat_cpu</code> - system %iowait</li> <li><code>iostat_device</code> - per-device I/O stats</li> <li><code>mpstat_core</code> - per-core CPU stats</li> <li><code>mpstat_summary</code> - CPU imbalance metrics</li> <li><code>vmstat</code> - memory pressure, swap</li> <li><code>node_state</code> - SLURM node allocation</li> <li><code>gpu_stats</code> - NVIDIA GPU metrics</li> <li><code>nfs_stats</code> - NFS I/O metrics</li> </ul>"},{"location":"ARCHITECTURE/#job-data","title":"Job Data","text":"<ul> <li><code>jobs</code> - job metadata from sacct</li> <li><code>job_metrics</code> - time-series job stats</li> <li><code>job_io_samples</code> - per-job I/O snapshots</li> <li><code>job_summary</code> - health scores, feature vectors</li> </ul>"},{"location":"ARCHITECTURE/#analysis","title":"Analysis","text":"<ul> <li><code>job_similarity</code> - pairwise similarity edges</li> <li><code>clusters</code> - job cluster profiles</li> <li><code>alerts</code> - alert history</li> <li><code>collection_log</code> - collector run history</li> </ul>"},{"location":"ARCHITECTURE/#cli-commands","title":"CLI Commands","text":"<pre><code># Core commands\nnomade status              # Full system overview\nnomade syscheck            # Verify requirements\nnomade collect --once      # Single collection cycle\nnomade collect -i 60       # Continuous (every 60s)\nnomade monitor -i 30       # Job I/O monitor (every 30s)\n\n# Analysis\nnomade disk /home          # Filesystem trends\nnomade jobs --user X       # Job history\nnomade similarity          # Similarity analysis\nnomade alerts              # View alerts\n\n# Bash helpers (source scripts/nomade.sh)\nnstatus    nwatch    ndisk    njobs    nsimilarity\nnalerts    ncollect  nmonitor nsyscheck nlog\n</code></pre>"},{"location":"ARCHITECTURE/#quick-start","title":"Quick Start","text":"<pre><code># 1. Initialize database\nsqlite3 /var/lib/nomade/nomade.db &lt; nomade/db/schema.sql\n\n# 2. Verify system\nnomade syscheck\n\n# 3. Test collection\nnomade collect --once\n\n# 4. Start continuous collection\nnohup nomade collect -i 60 &gt; /tmp/nomade-collect.log 2&gt;&amp;1 &amp;\nnohup nomade monitor -i 30 &gt; /tmp/nomade-monitor.log 2&gt;&amp;1 &amp;\n\n# 5. Check status\nnomade status\n</code></pre>"},{"location":"CONTRIBUTING/","title":"Contributing to NOMADE","text":"<p>Thank you for your interest in contributing to NOMADE! This document provides guidelines and information for contributors.</p>"},{"location":"CONTRIBUTING/#code-of-conduct","title":"Code of Conduct","text":"<p>By participating in this project, you agree to maintain a respectful and inclusive environment. We welcome contributors of all backgrounds and experience levels.</p>"},{"location":"CONTRIBUTING/#how-to-contribute","title":"How to Contribute","text":""},{"location":"CONTRIBUTING/#reporting-issues","title":"Reporting Issues","text":"<ul> <li>Bug reports: Use the GitHub issue tracker with the \"bug\" label</li> <li>Feature requests: Use the \"enhancement\" label</li> <li>Questions: Use the \"question\" label or start a discussion</li> </ul> <p>When reporting a bug, please include: - NOMADE version - Python version - Operating system - SLURM version (if relevant) - Steps to reproduce - Expected vs actual behavior - Error messages and logs</p>"},{"location":"CONTRIBUTING/#contributing-code","title":"Contributing Code","text":"<ol> <li>Fork the repository</li> <li>Create a branch for your feature (<code>git checkout -b feature/amazing-feature</code>)</li> <li>Make your changes following our coding standards</li> <li>Add tests for new functionality</li> <li>Run the test suite (<code>pytest</code>)</li> <li>Commit with a clear message</li> <li>Push to your branch</li> <li>Open a Pull Request</li> </ol>"},{"location":"CONTRIBUTING/#pull-request-guidelines","title":"Pull Request Guidelines","text":"<ul> <li>Keep PRs focused on a single feature or fix</li> <li>Update documentation if needed</li> <li>Add tests for new code</li> <li>Ensure all tests pass</li> <li>Follow the existing code style</li> <li>Write a clear PR description explaining your changes</li> </ul>"},{"location":"CONTRIBUTING/#development-setup","title":"Development Setup","text":"<pre><code># Clone your fork\ngit clone https://github.com/YOUR_USERNAME/nomade.git\ncd nomade\n\n# Create virtual environment\npython -m venv venv\nsource venv/bin/activate\n\n# Install in development mode with dev dependencies\npip install -e \".[dev]\"\n\n# Install pre-commit hooks\npre-commit install\n</code></pre>"},{"location":"CONTRIBUTING/#coding-standards","title":"Coding Standards","text":""},{"location":"CONTRIBUTING/#python-style","title":"Python Style","text":"<ul> <li>Follow PEP 8</li> <li>Use type hints for function signatures</li> <li>Maximum line length: 100 characters</li> <li>Use <code>ruff</code> for linting: <code>ruff check .</code></li> <li>Use <code>black</code> for formatting: <code>black .</code></li> </ul>"},{"location":"CONTRIBUTING/#documentation","title":"Documentation","text":"<ul> <li>Use docstrings for all public functions and classes</li> <li>Follow Google docstring format</li> <li>Update README.md for user-facing changes</li> <li>Update docs/ for detailed documentation</li> </ul>"},{"location":"CONTRIBUTING/#example-function","title":"Example Function","text":"<pre><code>def calculate_health_score(\n    metrics: dict[str, float],\n    weights: dict[str, float] | None = None,\n) -&gt; float:\n    \"\"\"\n    Calculate job health score from metrics.\n\n    Args:\n        metrics: Dictionary of metric name to value.\n            Expected keys: cpu_percent, mem_gb, nfs_write_gb, etc.\n        weights: Optional custom weights for each metric.\n            Defaults to empirically derived weights.\n\n    Returns:\n        Health score between 0.0 (catastrophic) and 1.0 (perfect).\n\n    Raises:\n        ValueError: If required metrics are missing.\n\n    Example:\n        &gt;&gt;&gt; metrics = {'cpu_percent': 85, 'nfs_write_gb': 50}\n        &gt;&gt;&gt; score = calculate_health_score(metrics)\n        &gt;&gt;&gt; print(f\"Health: {score:.2f}\")\n        Health: 0.72\n    \"\"\"\n    ...\n</code></pre>"},{"location":"CONTRIBUTING/#commit-messages","title":"Commit Messages","text":"<p>Follow the conventional commits format:</p> <pre><code>type(scope): brief description\n\nLonger description if needed.\n\nFixes #123\n</code></pre> <p>Types: - <code>feat</code>: New feature - <code>fix</code>: Bug fix - <code>docs</code>: Documentation only - <code>style</code>: Formatting, no code change - <code>refactor</code>: Code restructuring - <code>test</code>: Adding tests - <code>chore</code>: Maintenance tasks</p>"},{"location":"CONTRIBUTING/#testing","title":"Testing","text":""},{"location":"CONTRIBUTING/#running-tests","title":"Running Tests","text":"<pre><code># Run all tests\npytest\n\n# Run with coverage\npytest --cov=nomade --cov-report=html\n\n# Run specific test file\npytest tests/test_collectors.py\n\n# Run specific test\npytest tests/test_collectors.py::test_disk_collector\n</code></pre>"},{"location":"CONTRIBUTING/#writing-tests","title":"Writing Tests","text":"<ul> <li>Place tests in <code>tests/</code> directory</li> <li>Mirror the source structure (e.g., <code>tests/test_collectors/test_disk.py</code>)</li> <li>Use pytest fixtures for common setup</li> <li>Mock external dependencies (SLURM commands, filesystem, etc.)</li> </ul> <p>Example test:</p> <pre><code>import pytest\nfrom unittest.mock import patch, MagicMock\nfrom nomade.collectors.disk import DiskCollector\n\n@pytest.fixture\ndef disk_collector():\n    \"\"\"Create a DiskCollector with test configuration.\"\"\"\n    config = {\n        'filesystems': ['/home', '/scratch'],\n        'quota_enabled': False,\n    }\n    return DiskCollector(config)\n\ndef test_parse_df_output(disk_collector):\n    \"\"\"Test parsing of df command output.\"\"\"\n    df_output = \"\"\"Filesystem     1K-blocks      Used Available Use% Mounted on\n/dev/sda1      102400000  51200000  51200000  50% /home\"\"\"\n\n    result = disk_collector._parse_df_output(df_output)\n\n    assert len(result) == 1\n    assert result[0]['path'] == '/home'\n    assert result[0]['used_percent'] == 50.0\n\n@patch('subprocess.run')\ndef test_collect_filesystem_usage(mock_run, disk_collector):\n    \"\"\"Test filesystem usage collection.\"\"\"\n    mock_run.return_value = MagicMock(\n        returncode=0,\n        stdout=\"...\",  # df output\n    )\n\n    result = disk_collector.collect()\n\n    assert result is not None\n    mock_run.assert_called_once()\n</code></pre>"},{"location":"CONTRIBUTING/#project-structure","title":"Project Structure","text":"<pre><code>nomade/\n\u251c\u2500\u2500 nomade/              # Main package\n\u2502   \u251c\u2500\u2500 collectors/      # Data collectors\n\u2502   \u251c\u2500\u2500 db/             # Database layer\n\u2502   \u251c\u2500\u2500 analysis/       # Analysis utilities\n\u2502   \u251c\u2500\u2500 alerts/         # Alert system\n\u2502   \u251c\u2500\u2500 prediction/     # ML prediction\n\u2502   \u2514\u2500\u2500 viz/            # Visualization\n\u251c\u2500\u2500 tests/              # Test suite\n\u251c\u2500\u2500 docs/               # Documentation\n\u251c\u2500\u2500 scripts/            # Utility scripts\n\u2514\u2500\u2500 examples/           # Example configurations\n</code></pre>"},{"location":"CONTRIBUTING/#areas-for-contribution","title":"Areas for Contribution","text":""},{"location":"CONTRIBUTING/#high-priority","title":"High Priority","text":"<ul> <li>[ ] Additional SLURM metrics collection</li> <li>[ ] Prometheus export format</li> <li>[ ] Grafana dashboard templates</li> <li>[ ] More comprehensive test coverage</li> </ul>"},{"location":"CONTRIBUTING/#medium-priority","title":"Medium Priority","text":"<ul> <li>[ ] Additional license server types</li> <li>[ ] Custom alert dispatch channels</li> <li>[ ] Dark mode for dashboard</li> <li>[ ] Mobile-responsive dashboard</li> </ul>"},{"location":"CONTRIBUTING/#future-research","title":"Future / Research","text":"<ul> <li>[ ] GNN model implementation</li> <li>[ ] LSTM early warning system</li> <li>[ ] Federated learning across clusters</li> <li>[ ] Natural language alert summaries</li> </ul>"},{"location":"CONTRIBUTING/#getting-help","title":"Getting Help","text":"<ul> <li>Documentation: Check the <code>docs/</code> directory</li> <li>Issues: Search existing issues before creating new ones</li> <li>Discussions: Use GitHub Discussions for questions</li> <li>Email: [contact email]</li> </ul>"},{"location":"CONTRIBUTING/#license","title":"License","text":"<p>By contributing, you agree that your contributions will be licensed under the same license as the project (AGPL v3 for open source use).</p>"},{"location":"CONTRIBUTING/#recognition","title":"Recognition","text":"<p>Contributors will be recognized in: - The project README - Release notes - The AUTHORS file</p> <p>Thank you for contributing to NOMADE! \ud83c\udf89</p>"},{"location":"ROADMAP/","title":"NOMADE Development Roadmap","text":""},{"location":"ROADMAP/#timeline-overview","title":"Timeline Overview","text":"<pre><code>2025 Q1 (Jan-Mar)     Phase 1: Monitoring Foundation\n2025 Q2 (Apr-Jun)     Phase 2: Prediction Engine\n2025 Q3 (Jul-Sep)     Phase 3: Visualization &amp; Integration\n2025 Q4 (Oct-Dec)     Phase 4: Paper 1 &amp; Release\n2026 Q1-Q2            Phase 5: Advanced ML &amp; Paper 2\n</code></pre>"},{"location":"ROADMAP/#phase-1-monitoring-foundation-jan-mar-2025","title":"Phase 1: Monitoring Foundation (Jan-Mar 2025)","text":""},{"location":"ROADMAP/#milestone-11-core-infrastructure","title":"Milestone 1.1: Core Infrastructure","text":"<p>Target: End of January</p> <ul> <li>[ ] Database Layer</li> <li>[ ] SQLite schema design and implementation</li> <li>[ ] Data models (Python dataclasses)</li> <li>[ ] Query utilities</li> <li> <p>[ ] Migration system for schema updates</p> </li> <li> <p>[ ] Configuration System</p> </li> <li>[ ] TOML parser and validation</li> <li>[ ] Default configuration</li> <li>[ ] Environment variable overrides</li> <li> <p>[ ] Config hot-reload support</p> </li> <li> <p>[ ] Logging &amp; Error Handling</p> </li> <li>[ ] Structured logging setup</li> <li>[ ] Log rotation</li> <li>[ ] Error categorization</li> </ul>"},{"location":"ROADMAP/#milestone-12-collectors","title":"Milestone 1.2: Collectors","text":"<p>Target: End of February</p> <ul> <li>[ ] Base Collector Framework</li> <li>[ ] Abstract base class</li> <li>[ ] Collection scheduling</li> <li>[ ] Error handling and retry logic</li> <li> <p>[ ] Metrics storage interface</p> </li> <li> <p>[ ] Disk Collector</p> </li> <li>[ ] Filesystem usage (df parsing)</li> <li>[ ] Quota tracking (quota command)</li> <li>[ ] Fill rate calculation</li> <li>[ ] Derivative analysis integration</li> <li> <p>[ ] Large file detection</p> </li> <li> <p>[ ] SLURM Collector</p> </li> <li>[ ] Queue state (squeue)</li> <li>[ ] Job history (sacct)</li> <li>[ ] Node state (sinfo)</li> <li>[ ] Partition statistics</li> <li> <p>[ ] Pending job analysis</p> </li> <li> <p>[ ] Node Collector</p> </li> <li>[ ] Node status from SLURM</li> <li>[ ] SSH-based health checks</li> <li>[ ] Temperature monitoring (sensors, nvidia-smi)</li> <li>[ ] NFS mount verification</li> <li> <p>[ ] Service status checks</p> </li> <li> <p>[ ] License Collector</p> </li> <li>[ ] FlexLM query parsing</li> <li>[ ] RLM support</li> <li>[ ] Generic license server interface</li> <li>[ ] Expiration tracking</li> </ul>"},{"location":"ROADMAP/#milestone-13-alert-system","title":"Milestone 1.3: Alert System","text":"<p>Target: End of March</p> <ul> <li>[ ] Alert Engine</li> <li>[ ] Rule evaluation framework</li> <li>[ ] Threshold-based rules</li> <li>[ ] Derivative-based rules</li> <li>[ ] Alert deduplication</li> <li>[ ] Cooldown management</li> <li> <p>[ ] Severity levels</p> </li> <li> <p>[ ] Derivative Analysis</p> </li> <li>[ ] First derivative calculation</li> <li>[ ] Second derivative calculation</li> <li>[ ] Trend classification</li> <li>[ ] Projection (linear and quadratic)</li> <li> <p>[ ] Smoothing options</p> </li> <li> <p>[ ] Dispatch System</p> </li> <li>[ ] Email dispatcher</li> <li>[ ] Slack webhook dispatcher</li> <li>[ ] Generic webhook support</li> <li> <p>[ ] Alert acknowledgment tracking</p> </li> <li> <p>[ ] CLI Interface</p> </li> <li>[ ] <code>nomade init</code></li> <li>[ ] <code>nomade start/stop/status</code></li> <li>[ ] <code>nomade disk/queue/nodes/licenses</code></li> <li>[ ] <code>nomade alerts</code></li> </ul>"},{"location":"ROADMAP/#phase-1-deliverables","title":"Phase 1 Deliverables","text":"<ul> <li>Working monitoring daemon</li> <li>Email alerts for threshold and derivative triggers</li> <li>CLI for status checking</li> <li>SQLite database with historical data</li> <li>Basic documentation</li> </ul>"},{"location":"ROADMAP/#phase-2-prediction-engine-apr-jun-2025","title":"Phase 2: Prediction Engine (Apr-Jun 2025)","text":""},{"location":"ROADMAP/#milestone-21-job-metrics-collection","title":"Milestone 2.1: Job Metrics Collection","text":"<p>Target: End of April</p> <ul> <li>[ ] SLURM Hooks</li> <li>[ ] Prolog script (job start)</li> <li>[ ] Epilog script (job end)</li> <li>[ ] cgroup metrics extraction</li> <li>[ ] GPU metrics (nvidia-smi)</li> <li> <p>[ ] I/O metrics (from /proc or cgroup)</p> </li> <li> <p>[ ] Job Data Model</p> </li> <li>[ ] Job metadata table</li> <li>[ ] Job metrics table (time-series)</li> <li>[ ] Job summary table (computed at end)</li> <li>[ ] Health score storage</li> </ul>"},{"location":"ROADMAP/#milestone-22-similarity-network","title":"Milestone 2.2: Similarity Network","text":"<p>Target: End of May</p> <ul> <li>[ ] Feature Engineering</li> <li>[ ] Raw metric extraction</li> <li>[ ] Normalization (z-score, min-max)</li> <li>[ ] Non-redundant feature set</li> <li> <p>[ ] Feature correlation analysis</p> </li> <li> <p>[ ] Similarity Computation</p> </li> <li>[ ] Cosine similarity implementation</li> <li>[ ] Efficient pairwise computation</li> <li>[ ] Threshold-based edge creation</li> <li> <p>[ ] Network storage format</p> </li> <li> <p>[ ] Health Score Model</p> </li> <li>[ ] Initial formula (domain knowledge)</li> <li>[ ] Continuous score (0\u21921)</li> <li>[ ] Calibration against outcomes</li> <li>[ ] Cluster-based prediction</li> </ul>"},{"location":"ROADMAP/#milestone-23-simulation-validation","title":"Milestone 2.3: Simulation &amp; Validation","text":"<p>Target: End of June</p> <ul> <li>[ ] Generative Model</li> <li>[ ] Fit distributions to empirical data</li> <li>[ ] Profile-based simulation</li> <li>[ ] Correlation preservation</li> <li> <p>[ ] Synthetic job generation</p> </li> <li> <p>[ ] Validation Framework</p> </li> <li>[ ] Coverage analysis</li> <li>[ ] Anomaly detection</li> <li>[ ] Distribution comparison</li> <li> <p>[ ] Temporal drift monitoring</p> </li> <li> <p>[ ] Error Analysis</p> </li> <li>[ ] Confusion matrix computation</li> <li>[ ] Type 1/Type 2 error rates</li> <li>[ ] ROC curve generation</li> <li>[ ] Threshold optimization</li> <li> <p>[ ] Defaults derivation</p> </li> <li> <p>[ ] Recommendations</p> </li> <li>[ ] Feature impact analysis</li> <li>[ ] Threshold extraction</li> <li>[ ] User-specific suggestions</li> <li>[ ] Training identification</li> </ul>"},{"location":"ROADMAP/#phase-2-deliverables","title":"Phase 2 Deliverables","text":"<ul> <li>Per-job metrics collection via SLURM hooks</li> <li>Similarity network from real cluster data</li> <li>Health score prediction</li> <li>Data-driven recommendations</li> <li>Simulation validation framework</li> </ul>"},{"location":"ROADMAP/#phase-3-visualization-integration-jul-sep-2025","title":"Phase 3: Visualization &amp; Integration (Jul-Sep 2025)","text":""},{"location":"ROADMAP/#milestone-31-dashboard-backend","title":"Milestone 3.1: Dashboard Backend","text":"<p>Target: End of July</p> <ul> <li>[ ] API Server</li> <li>[ ] FastAPI or Flask backend</li> <li>[ ] REST endpoints for all data</li> <li>[ ] WebSocket for real-time updates</li> <li> <p>[ ] Authentication (optional)</p> </li> <li> <p>[ ] Data Aggregation</p> </li> <li>[ ] Time-series aggregation</li> <li>[ ] Rollup tables for performance</li> <li>[ ] Efficient queries for dashboard</li> </ul>"},{"location":"ROADMAP/#milestone-32-dashboard-frontend","title":"Milestone 3.2: Dashboard Frontend","text":"<p>Target: End of August</p> <ul> <li>[ ] Monitoring Views</li> <li>[ ] Disk usage dashboard</li> <li>[ ] Queue status display</li> <li>[ ] Node health grid</li> <li>[ ] License availability</li> <li> <p>[ ] Alert management</p> </li> <li> <p>[ ] Prediction Views</p> </li> <li>[ ] 2D similarity network</li> <li>[ ] Health score distribution</li> <li>[ ] Feature correlation panel</li> <li> <p>[ ] Recommendations display</p> </li> <li> <p>[ ] 3D Visualization</p> </li> <li>[ ] Three.js network rendering</li> <li>[ ] Interactive rotation/zoom</li> <li>[ ] Safe/danger zone display</li> <li>[ ] Simulation cloud overlay</li> <li>[ ] Real-time job tracking</li> </ul>"},{"location":"ROADMAP/#milestone-33-integration-testing","title":"Milestone 3.3: Integration &amp; Testing","text":"<p>Target: End of September</p> <ul> <li>[ ] End-to-End Testing</li> <li>[ ] Collector integration tests</li> <li>[ ] Alert system tests</li> <li>[ ] Prediction accuracy tests</li> <li> <p>[ ] Dashboard functional tests</p> </li> <li> <p>[ ] Documentation</p> </li> <li>[ ] Installation guide</li> <li>[ ] Configuration reference</li> <li>[ ] API documentation</li> <li> <p>[ ] User guide</p> </li> <li> <p>[ ] Performance Optimization</p> </li> <li>[ ] Database query optimization</li> <li>[ ] Collection efficiency</li> <li>[ ] Dashboard responsiveness</li> </ul>"},{"location":"ROADMAP/#phase-3-deliverables","title":"Phase 3 Deliverables","text":"<ul> <li>Complete web dashboard</li> <li>3D network visualization</li> <li>Real-time updates</li> <li>Comprehensive documentation</li> <li>Performance-tested system</li> </ul>"},{"location":"ROADMAP/#phase-4-paper-1-release-oct-dec-2025","title":"Phase 4: Paper 1 &amp; Release (Oct-Dec 2025)","text":""},{"location":"ROADMAP/#milestone-41-case-study","title":"Milestone 4.1: Case Study","text":"<p>Target: End of October</p> <ul> <li>[ ] Production Cluster Deployment</li> <li>[ ] Full deployment on Production Cluster</li> <li>[ ] 2+ months of production data</li> <li> <p>[ ] User feedback collection</p> </li> <li> <p>[ ] Metrics Collection</p> </li> <li>[ ] Alert effectiveness analysis</li> <li>[ ] Prediction accuracy metrics</li> <li>[ ] System overhead measurements</li> <li> <p>[ ] User satisfaction survey</p> </li> <li> <p>[ ] VM Simulation Environment</p> </li> <li>[ ] Data anonymization pipeline (remove users, paths, hostnames)</li> <li>[ ] Export tool for Production Cluster data \u2192 portable dataset</li> <li>[ ] Data replay engine (feed historical data as \"live\" events)</li> <li>[ ] Mock SLURM commands (squeue, sacct responses from data)</li> <li>[ ] VM image or Docker container with full NOMADE stack</li> <li>[ ] Documentation for reproducibility</li> </ul>"},{"location":"ROADMAP/#milestone-42-paper-writing","title":"Milestone 4.2: Paper Writing","text":"<p>Target: End of November</p> <ul> <li>[ ] Paper 1 Draft</li> <li>[ ] Introduction and motivation</li> <li>[ ] Architecture description</li> <li>[ ] Feature documentation</li> <li>[ ] Case study results</li> <li> <p>[ ] Performance analysis</p> </li> <li> <p>[ ] Figures and Tables</p> </li> <li>[ ] Architecture diagram</li> <li>[ ] Screenshot gallery</li> <li>[ ] Performance charts</li> <li>[ ] Comparison tables</li> </ul>"},{"location":"ROADMAP/#milestone-43-release","title":"Milestone 4.3: Release","text":"<p>Target: End of December</p> <ul> <li>[ ] Open Source Release</li> <li>[ ] Code cleanup</li> <li>[ ] License files</li> <li>[ ] GitHub repository setup</li> <li> <p>[ ] PyPI package</p> </li> <li> <p>[ ] Paper Submission</p> </li> <li>[ ] JOSS or SoftwareX submission</li> <li>[ ] Reviewer response preparation</li> </ul>"},{"location":"ROADMAP/#phase-4-deliverables","title":"Phase 4 Deliverables","text":"<ul> <li>Production deployment on Production Cluster</li> <li>Tool paper submitted</li> <li>Open source release v1.0</li> <li>PyPI package</li> </ul>"},{"location":"ROADMAP/#phase-5-advanced-ml-paper-2-2026-q1-q2","title":"Phase 5: Advanced ML &amp; Paper 2 (2026 Q1-Q2)","text":""},{"location":"ROADMAP/#milestone-51-advanced-models","title":"Milestone 5.1: Advanced Models","text":"<p>Target: End of February 2026</p> <ul> <li>[ ] GNN Implementation</li> <li>[ ] PyTorch Geometric setup</li> <li>[ ] Graph construction from similarity network</li> <li>[ ] Node-level prediction (job health)</li> <li> <p>[ ] Training pipeline</p> </li> <li> <p>[ ] LSTM Early Warning</p> </li> <li>[ ] Time-series feature extraction</li> <li>[ ] Derivative features</li> <li>[ ] Early warning prediction</li> <li> <p>[ ] Alert integration</p> </li> <li> <p>[ ] Ensemble Methods</p> </li> <li>[ ] Model combination</li> <li>[ ] Confidence estimation</li> <li>[ ] Disagreement detection</li> </ul>"},{"location":"ROADMAP/#milestone-52-partnerships","title":"Milestone 5.2: Partnerships","text":"<p>Target: End of April 2026</p> <ul> <li>[ ] Partner Outreach</li> <li>[ ] Contact potential partners</li> <li>[ ] Data sharing agreements</li> <li> <p>[ ] Deployment assistance</p> </li> <li> <p>[ ] Multi-Cluster Data</p> </li> <li>[ ] Anonymization pipeline</li> <li>[ ] Cross-cluster analysis</li> <li>[ ] Universal vs local patterns</li> </ul>"},{"location":"ROADMAP/#milestone-53-paper-2","title":"Milestone 5.3: Paper 2","text":"<p>Target: Summer 2026</p> <ul> <li>[ ] Research Analysis</li> <li>[ ] Emergent pattern discovery</li> <li>[ ] Biogeographical analogy validation</li> <li>[ ] Prediction vs baseline comparison</li> <li> <p>[ ] Cross-institution validation</p> </li> <li> <p>[ ] Paper 2 Writing</p> </li> <li>[ ] Methods focus</li> <li>[ ] Theoretical framework</li> <li>[ ] Multi-cluster results</li> <li>[ ] Nature Computational Science target</li> </ul>"},{"location":"ROADMAP/#phase-5-deliverables","title":"Phase 5 Deliverables","text":"<ul> <li>GNN and LSTM models</li> <li>Multi-cluster deployment</li> <li>Paper 2 submitted</li> <li>Community data federation</li> </ul>"},{"location":"ROADMAP/#task-tracking","title":"Task Tracking","text":""},{"location":"ROADMAP/#priority-labels","title":"Priority Labels","text":"<ul> <li>\ud83d\udd34 P0: Critical path, blocks other work</li> <li>\ud83d\udfe0 P1: Important, should be done soon</li> <li>\ud83d\udfe1 P2: Nice to have, can be deferred</li> <li>\ud83d\udfe2 P3: Future enhancement</li> </ul>"},{"location":"ROADMAP/#status-labels","title":"Status Labels","text":"<ul> <li>\u2b1c Not started</li> <li>\ud83d\udfe8 In progress</li> <li>\u2705 Complete</li> <li>\u274c Blocked</li> </ul>"},{"location":"ROADMAP/#dependencies","title":"Dependencies","text":""},{"location":"ROADMAP/#external-dependencies","title":"External Dependencies","text":"<ul> <li>Python 3.9+</li> <li>SQLite 3.35+</li> <li>SLURM (for queue monitoring)</li> <li>nvidia-smi (for GPU monitoring)</li> <li>React/Three.js (for visualization)</li> </ul>"},{"location":"ROADMAP/#python-dependencies","title":"Python Dependencies","text":"<pre><code># Core\ntoml&gt;=0.10\nclick&gt;=8.0\nsqlalchemy&gt;=2.0\n\n# Analysis\nnumpy&gt;=1.21\nscipy&gt;=1.7\npandas&gt;=1.3\n\n# Prediction (Phase 2)\nscikit-learn&gt;=1.0\ntorch&gt;=2.0\ntorch-geometric&gt;=2.0\n\n# Visualization (Phase 3)\nfastapi&gt;=0.100\nuvicorn&gt;=0.20\njinja2&gt;=3.0\n\n# Development\npytest&gt;=7.0\nruff&gt;=0.1\nblack&gt;=23.0\n</code></pre>"},{"location":"ROADMAP/#risk-mitigation","title":"Risk Mitigation","text":"Risk Impact Mitigation SLURM access restrictions Can't collect job metrics Fallback to sacct-only data No root on cluster Limited cgroup access Use available SLURM data ML model underperforms Poor predictions Start with simple rules, add ML later Dashboard too complex Delayed release MVP first, enhance iteratively Partner data unavailable Paper 2 scope limited Focus on single-cluster depth"},{"location":"ROADMAP/#success-metrics","title":"Success Metrics","text":""},{"location":"ROADMAP/#phase-1","title":"Phase 1","text":"<ul> <li>[ ] Monitoring daemon runs 7+ days without crash</li> <li>[ ] Alerts delivered within 60 seconds of trigger</li> <li>[ ] &lt;1% CPU overhead on head node</li> </ul>"},{"location":"ROADMAP/#phase-2","title":"Phase 2","text":"<ul> <li>[ ] &gt;80% jobs have metrics collected</li> <li>[ ] Prediction accuracy &gt;70%</li> <li>[ ] Recommendations improve success rate by &gt;10%</li> </ul>"},{"location":"ROADMAP/#phase-3","title":"Phase 3","text":"<ul> <li>[ ] Dashboard loads in &lt;3 seconds</li> <li>[ ] 3D visualization runs at 30+ FPS</li> <li>[ ] Real-time updates within 5 seconds</li> </ul>"},{"location":"ROADMAP/#phase-4","title":"Phase 4","text":"<ul> <li>[ ] Paper 1 submitted to JOSS/SoftwareX</li> <li>[ ] &gt;10 GitHub stars within 3 months</li> <li>[ ] At least 1 external deployment inquiry</li> </ul>"},{"location":"ROADMAP/#zfs-support-enhancement","title":"ZFS Support Enhancement","text":"<p>Status: Planned</p>"},{"location":"ROADMAP/#current-compatibility","title":"Current Compatibility","text":"<ul> <li>Basic monitoring via <code>df</code> and <code>iostat</code> works on ZFS systems</li> <li>Quotas via <code>zfs get userquota</code> not yet supported</li> </ul>"},{"location":"ROADMAP/#planned-features","title":"Planned Features","text":"<ol> <li>Auto-detection: Check for <code>/proc/spl/kstat/zfs</code> or <code>zpool</code> command</li> <li>ZFS Collector (<code>nomade/collectors/zfs.py</code>):</li> <li>Pool health via <code>zpool status</code></li> <li>Per-vdev I/O via <code>zpool iostat -v</code></li> <li>ARC cache stats from <code>/proc/spl/kstat/zfs/arcstats</code></li> <li>Compression/dedup ratios via <code>zfs get</code></li> <li>ZFS Quotas: Support <code>zfs get userquota@user dataset</code></li> <li>Config option: <code>storage_backend = \"auto\" | \"traditional\" | \"zfs\"</code></li> </ol>"},{"location":"ROADMAP/#priority-metrics","title":"Priority Metrics","text":"Metric Source Why Pool health <code>zpool status</code> Critical for failure prediction ARC hit ratio arcstats Memory efficiency Latency histograms <code>zpool iostat -l</code> I/O performance"},{"location":"alerts/","title":"Alerts","text":"<p>N\u00d8MADE supports both threshold-based and predictive alerts.</p>"},{"location":"alerts/#alert-types","title":"Alert Types","text":""},{"location":"alerts/#threshold-alerts","title":"Threshold Alerts","text":"<p>Trigger when metrics exceed configured limits: - Disk usage &gt; 95% - GPU temperature &gt; 85\u00b0C - Memory pressure &gt; 90%</p>"},{"location":"alerts/#predictive-alerts","title":"Predictive Alerts","text":"<p>Trigger when trends indicate future problems: - Disk fill rate predicts full in &lt; 24 hours - Memory pressure accelerating - I/O wait increasing</p>"},{"location":"alerts/#backends","title":"Backends","text":""},{"location":"alerts/#email","title":"Email","text":"<pre><code>[alerts.email]\nenabled = true\nsmtp_host = \"smtp.example.edu\"\nsmtp_port = 587\nfrom_addr = \"nomade@example.edu\"\nto_addrs = [\"admin@example.edu\", \"hpc-team@example.edu\"]\n</code></pre>"},{"location":"alerts/#slack","title":"Slack","text":"<pre><code>[alerts.slack]\nenabled = true\nwebhook_url = \"https://hooks.slack.com/services/T00/B00/xxx\"\nchannel = \"#hpc-alerts\"\n</code></pre>"},{"location":"alerts/#webhook","title":"Webhook","text":"<pre><code>[alerts.webhook]\nenabled = true\nurl = \"https://your-service.example.edu/alerts\"\nheaders = { Authorization = \"Bearer xxx\" }\n</code></pre>"},{"location":"alerts/#cli","title":"CLI","text":"<pre><code># View recent alerts\nnomade alerts\n\n# Unresolved only\nnomade alerts --unresolved\n\n# Test alert backends\nnomade alerts test\n</code></pre>"},{"location":"alerts/#cooldowns","title":"Cooldowns","text":"<p>To prevent alert floods: <pre><code>[alerts]\ncooldown_minutes = 30  # Same alert won't repeat for 30 min\n</code></pre></p>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#v121-february-2026","title":"v1.2.1 (February 2026)","text":""},{"location":"changelog/#features","title":"Features","text":"<ul> <li>Proficiency score persistence to database</li> <li>Light/dark theme toggle in dashboard</li> <li>Combined edu figure in documentation</li> </ul>"},{"location":"changelog/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>Fixed <code>_resolve_db_path</code> error in edu commands</li> <li>Text wrapping for recommendations output</li> </ul>"},{"location":"changelog/#documentation","title":"Documentation","text":"<ul> <li>Expanded Educational Analytics section in paper</li> <li>Added Community Data Sharing details</li> <li>Reordered bibliography to match citation order</li> </ul>"},{"location":"changelog/#v120-january-2026","title":"v1.2.0 (January 2026)","text":""},{"location":"changelog/#features_1","title":"Features","text":"<ul> <li>Educational Analytics module (<code>nomade edu</code>)</li> <li>Community dataset export (<code>nomade community</code>)</li> <li>Multi-cluster dashboard tabs</li> <li>Interactive session monitoring</li> <li>3D force-directed network visualization</li> </ul>"},{"location":"changelog/#improvements","title":"Improvements","text":"<ul> <li>Partition-specific dashboard views</li> <li>Node health reflects CPU/memory pressure</li> <li>Failed jobs modal with categories</li> </ul>"},{"location":"changelog/#v110-december-2025","title":"v1.1.0 (December 2025)","text":""},{"location":"changelog/#features_2","title":"Features","text":"<ul> <li>ML prediction ensemble (GNN, LSTM, Autoencoder)</li> <li>Derivative analysis for trend detection</li> <li>Slack and webhook alert backends</li> </ul>"},{"location":"changelog/#v100-november-2025","title":"v1.0.0 (November 2025)","text":"<p>Initial release.</p>"},{"location":"cli/","title":"CLI Reference","text":""},{"location":"cli/#core-commands","title":"Core Commands","text":"Command Description <code>nomade init</code> Setup wizard <code>nomade collect</code> Start data collection <code>nomade dashboard</code> Launch web interface <code>nomade demo</code> Demo mode with synthetic data <code>nomade status</code> System status <code>nomade syscheck</code> Verify requirements"},{"location":"cli/#educational-analytics","title":"Educational Analytics","text":"Command Description <code>nomade edu explain &lt;job_id&gt;</code> Analyze job with recommendations <code>nomade edu trajectory &lt;user&gt;</code> User proficiency over time <code>nomade edu report &lt;group&gt;</code> Group/course report <p>Options for all edu commands: - <code>--db PATH</code> \u2014 Database path - <code>--json</code> \u2014 JSON output - <code>--days N</code> \u2014 Lookback period (trajectory/report)</p>"},{"location":"cli/#analysis","title":"Analysis","text":"Command Description <code>nomade disk &lt;path&gt;</code> Filesystem trends <code>nomade jobs</code> Job history <code>nomade similarity</code> Network analysis <code>nomade alerts</code> View alerts"},{"location":"cli/#ml-prediction","title":"ML &amp; Prediction","text":"Command Description <code>nomade train</code> Train prediction models <code>nomade predict</code> Run predictions <code>nomade report</code> Generate ML report"},{"location":"cli/#community-dataset","title":"Community Dataset","text":"Command Description <code>nomade community export</code> Export anonymized data <code>nomade community preview</code> Preview export <code>nomade community verify</code> Verify export integrity"},{"location":"cli/#data-collection","title":"Data Collection","text":"<pre><code># Continuous collection\nnomade collect\n\n# Single cycle\nnomade collect --once\n\n# Specific collectors\nnomade collect -C disk,slurm,groups\n</code></pre>"},{"location":"cli/#global-options","title":"Global Options","text":"Option Description <code>--config PATH</code> Config file path <code>--db PATH</code> Database path <code>--verbose</code> / <code>-v</code> Verbose output <code>--quiet</code> / <code>-q</code> Suppress output <code>--help</code> Show help"},{"location":"config/","title":"Configuration","text":"<p>N\u00d8MADE uses TOML configuration files.</p>"},{"location":"config/#configuration-locations","title":"Configuration Locations","text":"Install Type Path User <code>~/.config/nomade/nomade.toml</code> System <code>/etc/nomade/nomade.toml</code>"},{"location":"config/#example-configuration","title":"Example Configuration","text":"<pre><code># nomade.toml\n\n[general]\ncluster_name = \"spydur\"\ndata_dir = \"/var/lib/nomade\"\nlog_level = \"INFO\"\n\n[database]\npath = \"/var/lib/nomade/nomade.db\"\n\n[collectors]\nenabled = [\"disk\", \"iostat\", \"slurm\", \"gpu\", \"nfs\"]\ninterval = 60  # seconds\n\n[collectors.disk]\nfilesystems = [\"/\", \"/home\", \"/scratch\"]\nquota_enabled = true\n\n[collectors.slurm]\npartitions = [\"compute\", \"gpu\", \"highmem\"]\n\n[dashboard]\nhost = \"127.0.0.1\"\nport = 8050\n\n[alerts]\nenabled = true\n\n[alerts.email]\nenabled = true\nsmtp_host = \"smtp.example.edu\"\nfrom_addr = \"nomade@example.edu\"\nto_addrs = [\"admin@example.edu\"]\n\n[alerts.slack]\nenabled = true\nwebhook_url = \"https://hooks.slack.com/services/...\"\n\n[alerts.thresholds]\ndisk_warning = 85\ndisk_critical = 95\ngpu_temp_warning = 80\n\n[ml]\nenabled = true\nsimilarity_threshold = 0.7\n</code></pre>"},{"location":"config/#environment-variables","title":"Environment Variables","text":"Variable Description <code>NOMADE_CONFIG</code> Config file path <code>NOMADE_DB</code> Database path <code>NOMADE_LOG_LEVEL</code> Log level (DEBUG, INFO, WARNING, ERROR)"},{"location":"config/#collectors","title":"Collectors","text":"<p>See ARCHITECTURE.md for detailed collector documentation.</p>"},{"location":"dashboard/","title":"Dashboard","text":"<p>The N\u00d8MADE dashboard provides real-time monitoring of your HPC cluster(s).</p>"},{"location":"dashboard/#launching","title":"Launching","text":"<pre><code>nomade dashboard\n</code></pre> <p>Open http://localhost:8050 in your browser.</p>"},{"location":"dashboard/#tabs","title":"Tabs","text":""},{"location":"dashboard/#cluster-tabs","title":"Cluster Tabs","text":"<p>Per-cluster views showing: - Node status (idle, allocated, down) - Partition utilization - CPU and memory pressure indicators - Active jobs count</p>"},{"location":"dashboard/#network","title":"Network","text":"<p>3D job similarity network visualization: - Jobs as nodes, colored by health - Edges connect similar jobs - \"Safe zone\" and \"danger zone\" regions emerge from data - Failure clustering analysis</p>"},{"location":"dashboard/#resources","title":"Resources","text":"<p>Resource usage views for administrators: - CPU hours by cluster/group - Filter by cluster, group, and time period - Resource consumption patterns - Quietest hours for job scheduling</p>"},{"location":"dashboard/#activity","title":"Activity","text":"<p>Job activity and history: - Recent job completions - Failed job categories - Interactive session monitoring (RStudio/Jupyter)</p>"},{"location":"dashboard/#planned-features","title":"Planned Features","text":"<ul> <li>Education Tab: Visual proficiency trajectories and per-student breakdowns (CLI available now via <code>nomade edu</code>)</li> </ul>"},{"location":"dashboard/#remote-access","title":"Remote Access","text":"<p>By default, the dashboard only listens on localhost. For remote access:</p> <ol> <li> <p>SSH Tunnel (simple): <pre><code>   ssh -L 8050:localhost:8050 user@hpc-head\n</code></pre></p> </li> <li> <p>Reverse Proxy (production):    See System Install</p> </li> </ol>"},{"location":"edu/","title":"Educational Analytics","text":"<p>N\u00d8MADE Edu bridges the gap between infrastructure monitoring and educational outcomes, helping instructors, mentors, and users track the development of computational proficiency.</p>"},{"location":"edu/#overview","title":"Overview","text":"<p>Traditional HPC metrics tell you what happened. N\u00d8MADE Edu tells you how well users are learning to use HPC effectively.</p> <p>Use cases:</p> <ul> <li>Instructors: Track class-wide skill development, identify struggling students</li> <li>Research mentors: Monitor graduate student onboarding progress</li> <li>HPC staff: Evaluate workshop and training effectiveness</li> <li>Users: Self-assess and improve HPC practices</li> </ul>"},{"location":"edu/#quick-start","title":"Quick Start","text":"<pre><code># Explain a job with proficiency scores and recommendations\nnomade edu explain 12345\n\n# Track a user's improvement over time\nnomade edu trajectory alice\n\n# Generate a report for a course or research group\nnomade edu report cs301\n</code></pre>"},{"location":"edu/#commands","title":"Commands","text":""},{"location":"edu/#nomade-edu-explain","title":"<code>nomade edu explain</code>","text":"<p>Analyze a single job with proficiency scores and actionable recommendations. <pre><code>nomade edu explain &lt;job_id&gt; [options]\n</code></pre></p> <p>Options:</p> Option Description <code>--db PATH</code> Database path (default: configured DB) <code>--json</code> Output as JSON <code>--no-progress</code> Skip historical comparison <p>Example output: <pre><code>  N\u00d8MADE Job Analysis \u2014 1104\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  User: alice    Partition: compute    Node: node03\n  State: COMPLETED    Runtime: 33h 38m / 48h 00m requested\n\n  Proficiency Scores\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    CPU Efficiency       \u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591   22.6%   Needs Work\n    Memory Efficiency    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591   90.4%   Excellent\n    Time Estimation      \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588   97.4%   Excellent\n    I/O Awareness        \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591   68.8%   Good\n    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    Overall Score        \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591   69.8%   Good\n\n  Recommendations\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    CPU Efficiency:\n      Very low CPU utilization at 21% \u2014 requested 4\n      cores but used ~1. This wastes resources and\n      may delay other users' jobs.\n      Try: #SBATCH --ntasks=1\n          If your code is single-threaded, request 1 core.\n\n  Your Progress (last 30 jobs)\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    CPU Efficiency        53.7% \u2192  22.6%  \u2193 declining\n    Memory Efficiency     90.0% \u2192  90.4%  \u2192 stable\n    Time Estimation       88.4% \u2192  97.4%  \u2191 improving\n    I/O Awareness         91.8% \u2192  68.8%  \u2193 declining\n</code></pre></p>"},{"location":"edu/#nomade-edu-trajectory","title":"<code>nomade edu trajectory</code>","text":"<p>Track a user's proficiency development over time. <pre><code>nomade edu trajectory &lt;username&gt; [options]\n</code></pre></p> <p>Options:</p> Option Description <code>--db PATH</code> Database path <code>--days N</code> Lookback period (default: 90) <code>--json</code> Output as JSON <p>Example output: <pre><code>  N\u00d8MADE Proficiency Trajectory \u2014 alice\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  Jobs analyzed: 173    Period: 2026-02-04 \u2192 2026-02-15\n  Stable proficiency\n\n  Score Progression\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    2026-01-29    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591   78.6%  (21 jobs)\n    2026-02-05    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591   78.9%  (144 jobs)\n\n  Dimension Changes\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    I/O Awareness         90.6%  \u2192 +4.6%\n    Memory Efficiency     85.9%  \u2192 +0.2%\n    GPU Utilization       85.0%  \u2192 +0.0%\n    CPU Efficiency        51.9%  \u2192 -1.2%\n    Time Estimation       81.3%  \u2192 -2.1%\n</code></pre></p>"},{"location":"edu/#nomade-edu-report","title":"<code>nomade edu report</code>","text":"<p>Generate aggregate reports for courses, research groups, or any Linux group. <pre><code>nomade edu report &lt;group_name&gt; [options]\n</code></pre></p> <p>Options:</p> Option Description <code>--db PATH</code> Database path <code>--days N</code> Lookback period (default: 90) <code>--json</code> Output as JSON <p>Example output: <pre><code>  N\u00d8MADE Group Report \u2014 cs101\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  Members: 4     Jobs: 602\n  Period: 2026-02-04 \u2192 2026-02-16\n\n  Key Insight\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    0/4 students improved overall proficiency\n\n  Group Proficiency\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    Memory Efficiency    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591   85.2%  \u2192 -0.8%\n    GPU Utilization      \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591   85.0%  \u2192 +0.0%\n    I/O Awareness        \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591   80.2%  \u2192 -1.5%\n    Time Estimation      \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591   78.9%  \u2192 -1.1%\n    CPU Efficiency       \u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591   51.9%  \u2192 -2.4%\n\n    Weakest area:   cpu   |   Strongest: memory\n\n  Student Breakdown\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    Improving:   0\n    Stable:      4\n    Declining:   0\n\n  Per-Student Summary\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    User        Jobs    Overall   Change    Trend\n    charlie      136     73.2%    +0.7%       \u2192\n    alice        173     78.9%    +0.3%       \u2192\n    diana        147     76.8%    +0.1%       \u2192\n    bob          146     76.1%    -3.0%       \u2192\n</code></pre></p>"},{"location":"edu/#setting-up-groups","title":"Setting Up Groups","text":"<p>N\u00d8MADE uses Linux groups for course/lab membership. To track a class:</p>"},{"location":"edu/#option-1-use-existing-linux-groups","title":"Option 1: Use existing Linux groups","text":"<p>If your users are already in groups (e.g., <code>bio301</code>, <code>cs101</code>): <pre><code># Collect group membership\nnomade collect -C groups --once\n\n# Generate report\nnomade edu report bio301\n</code></pre></p>"},{"location":"edu/#option-2-create-dedicated-groups","title":"Option 2: Create dedicated groups","text":"<pre><code># Create group for course\nsudo groupadd cs301\n\n# Add students\nsudo usermod -aG cs301 student01\nsudo usermod -aG cs301 student02\n# ...\n\n# Collect and report\nnomade collect -C groups --once\nnomade edu report cs301\n</code></pre>"},{"location":"edu/#option-3-manual-group-file","title":"Option 3: Manual group file","text":"<p>Create a CSV file and import: <pre><code>username,group_name,gid,cluster\nalice,cs301,3001,spydur\nbob,cs301,3001,spydur\n</code></pre> <pre><code>nomade edu import-groups groups.csv\n</code></pre></p>"},{"location":"edu/#dashboard-integration","title":"Dashboard Integration","text":"<p>The dashboard includes an Education tab showing:</p> <ul> <li>Class-wide proficiency distributions</li> <li>Individual student progress</li> <li>Common problem areas</li> <li>Improvement trends over time</li> </ul> <p>Access via: <code>nomade dashboard</code> \u2192 Education tab</p>"},{"location":"edu/#best-practices","title":"Best Practices","text":""},{"location":"edu/#for-instructors","title":"For Instructors","text":"<ol> <li>Baseline early: Collect data from the first week to establish starting points</li> <li>Check weekly: Review group reports to identify struggling students early</li> <li>Focus on trends: Individual job scores vary; trajectories matter more</li> <li>Share reports: Let students see class-wide (anonymized) progress</li> </ol>"},{"location":"edu/#for-mentors","title":"For Mentors","text":"<ol> <li>Onboarding checkpoint: Review trajectory after first 10 jobs</li> <li>Specific feedback: Use <code>explain</code> output to guide discussions</li> <li>Celebrate improvement: Recognize when dimensions improve</li> </ol>"},{"location":"edu/#for-users","title":"For Users","text":"<ol> <li>Review failed jobs: Use <code>explain</code> to understand what went wrong</li> <li>Track your trajectory: Check weekly to see improvement</li> <li>Act on recommendations: The suggestions are data-driven</li> </ol>"},{"location":"edu/#technical-details","title":"Technical Details","text":"<p>For detailed information on how proficiency is computed:</p> <ul> <li>Proficiency Scoring \u2014 Formulas, dimensions, and scoring rubrics</li> <li>Database Schema \u2014 How scores are stored</li> </ul>"},{"location":"edu/#troubleshooting","title":"Troubleshooting","text":""},{"location":"edu/#job-not-found-in-database","title":"\"Job not found in database\"","text":"<pre><code>Job 12345 not found in database.\n\nHint: Specify a database with --db or run 'nomade init' to configure.\n  Example: nomade edu explain 12345 --db ~/nomade_demo.db\n</code></pre> <p>Solutions:</p> <ol> <li>Specify the database: <code>nomade edu explain 12345 --db /path/to/db</code></li> <li>Run <code>nomade init</code> to configure the default database</li> <li>Ensure data collection is running: <code>nomade collect</code></li> </ol>"},{"location":"edu/#not-enough-data-for-user","title":"\"Not enough data for user\"","text":"<p>The user needs at least 3 completed jobs for trajectory analysis.</p>"},{"location":"edu/#no-data-found-for-group","title":"\"No data found for group\"","text":"<p>Ensure group membership data has been collected: <pre><code>nomade collect -C groups --once\n</code></pre></p>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#quick-install","title":"Quick Install","text":"<pre><code>pip install nomade-hpc\n</code></pre>"},{"location":"installation/#from-source","title":"From Source","text":"<pre><code>git clone https://github.com/jtonini/nomade.git\ncd nomade\npip install -e .\n</code></pre>"},{"location":"installation/#requirements","title":"Requirements","text":""},{"location":"installation/#required","title":"Required","text":"Component Version Purpose Python 3.9+ Core runtime SQLite 3.35+ Data storage sysstat any <code>iostat</code>, <code>mpstat</code> collectors"},{"location":"installation/#optional","title":"Optional","text":"Component Purpose SLURM Job-level analytics, queue monitoring nvidia-smi GPU monitoring nfsiostat NFS I/O metrics"},{"location":"installation/#verify-installation","title":"Verify Installation","text":"<pre><code># Check requirements\nnomade syscheck\n\n# Test with demo data\nnomade demo\n</code></pre>"},{"location":"installation/#installation-types","title":"Installation Types","text":""},{"location":"installation/#user-install-default","title":"User Install (Default)","text":"<p>For personal use or testing: <pre><code>pip install nomade-hpc\nnomade init\n</code></pre></p> <p>Paths: <pre><code>~/.config/nomade/nomade.toml    # Configuration\n~/.local/share/nomade/          # Database, models, logs\n</code></pre></p>"},{"location":"installation/#system-install","title":"System Install","text":"<p>For production cluster-wide deployment: <pre><code>sudo pip install nomade-hpc\nsudo nomade init --system\n</code></pre></p> <p>Paths: <pre><code>/etc/nomade/nomade.toml         # Configuration\n/var/lib/nomade/                # Database, models\n/var/log/nomade/                # Logs\n</code></pre></p> <p>See System Install for detailed permissions and setup.</p>"},{"location":"installation/#virtual-environment","title":"Virtual Environment","text":"<p>Recommended for isolated installation: <pre><code>python -m venv ~/nomade-env\nsource ~/nomade-env/bin/activate\npip install nomade-hpc\n</code></pre></p>"},{"location":"installation/#conda-environment","title":"Conda Environment","text":"<pre><code>conda create -n nomade python=3.11\nconda activate nomade\npip install nomade-hpc\n</code></pre>"},{"location":"installation/#development-install","title":"Development Install","text":"<p>For contributing: <pre><code>git clone https://github.com/jtonini/nomade.git\ncd nomade\npython -m venv venv\nsource venv/bin/activate\npip install -e \".[dev]\"\npytest\n</code></pre></p>"},{"location":"installation/#upgrading","title":"Upgrading","text":"<pre><code>pip install --upgrade nomade-hpc\n</code></pre>"},{"location":"installation/#uninstalling","title":"Uninstalling","text":"<pre><code>pip uninstall nomade-hpc\n\n# Optional: remove data\nrm -rf ~/.config/nomade ~/.local/share/nomade\n</code></pre>"},{"location":"interactive/","title":"Interactive Session Monitoring","text":"<p>Monitor RStudio and Jupyter sessions across your cluster.</p>"},{"location":"interactive/#overview","title":"Overview","text":"<p>N\u00d8MADE tracks interactive computing sessions to identify: - Idle sessions consuming resources - Memory-heavy notebooks - Stale sessions (no activity for days) - Resource hogs</p>"},{"location":"interactive/#commands","title":"Commands","text":"<pre><code># Full report\nnomade report-interactive\n\n# Alerts only (idle/stale sessions)\nnomade report-interactive --quiet\n\n# JSON output\nnomade report-interactive --json\n</code></pre>"},{"location":"interactive/#report-output","title":"Report Output","text":"<pre><code>Interactive Sessions Report\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nRStudio Sessions: 12 active\n  node01: 3 sessions (2 idle &gt; 1hr)\n  node02: 5 sessions\n  node04: 4 sessions (1 idle &gt; 4hr)\n\nJupyter Sessions: 8 active\n  node01: 2 sessions\n  node03: 6 sessions (3 stale &gt; 24hr)\n\nRecommendations:\n  \u2022 5 sessions idle &gt; 1 hour \u2014 consider auto-timeout\n  \u2022 3 notebooks stale &gt; 24 hours \u2014 notify users\n</code></pre>"},{"location":"interactive/#jupyterhub-integration","title":"JupyterHub Integration","text":"<p>N\u00d8MADE can integrate with JupyterHub's idle-culler: <pre><code>[interactive.jupyter]\nhub_api_url = \"http://jupyterhub:8081/hub/api\"\napi_token = \"...\"\nidle_timeout_minutes = 60\n</code></pre></p>"},{"location":"interactive/#dashboard","title":"Dashboard","text":"<p>The Interactive tab in the dashboard shows live session status with: - Per-node session counts - Idle time indicators - Memory usage per session - One-click idle session alerts</p>"},{"location":"ml/","title":"ML Framework","text":"<p>N\u00d8MADE's machine learning framework combines multiple models for robust job failure prediction.</p>"},{"location":"ml/#architecture-overview","title":"Architecture Overview","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    ML Prediction Pipeline                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                 \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502  \u2502 Job Data \u2502\u2500\u2500\u2500\u25b6\u2502           Feature Engineering            \u2502   \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                    \u2502                            \u2502\n\u2502                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510            \u2502\n\u2502                    \u25bc               \u25bc               \u25bc            \u2502\n\u2502              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u2502\n\u2502              \u2502   GNN    \u2502   \u2502   LSTM   \u2502   \u2502 Autoencoder  \u2502     \u2502\n\u2502              \u2502 (Graph)  \u2502   \u2502 (Temporal)\u2502   \u2502  (Anomaly)  \u2502     \u2502\n\u2502              \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502\n\u2502                   \u2502              \u2502                \u2502             \u2502\n\u2502                   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518             \u2502\n\u2502                                  \u25bc                              \u2502\n\u2502                         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                        \u2502\n\u2502                         \u2502   Ensemble   \u2502                        \u2502\n\u2502                         \u2502   Combiner   \u2502                        \u2502\n\u2502                         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                        \u2502\n\u2502                                \u2502                                \u2502\n\u2502                                \u25bc                                \u2502\n\u2502                      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                        \u2502\n\u2502                      \u2502  Risk Score     \u2502                        \u2502\n\u2502                      \u2502   (0.0 - 1.0)   \u2502                        \u2502\n\u2502                      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"ml/#model-components","title":"Model Components","text":""},{"location":"ml/#1-graph-neural-network-gnn","title":"1. Graph Neural Network (GNN)","text":"<p>The GNN leverages the job similarity network structure to propagate failure signals.</p> <p>Intuition: Jobs connected in the similarity network share behavioral profiles. If a job's neighbors have high failure rates, the job itself is at elevated risk.</p> <p>Architecture: <pre><code>Input: Node features (17-dim) + Adjacency matrix\n  \u2502\n  \u25bc\nGraphConv Layer (17 \u2192 64, ReLU)\n  \u2502\n  \u25bc\nGraphConv Layer (64 \u2192 32, ReLU)\n  \u2502\n  \u25bc\nGlobal Mean Pooling\n  \u2502\n  \u25bc\nDense Layer (32 \u2192 1, Sigmoid)\n  \u2502\n  \u25bc\nOutput: Failure probability\n</code></pre></p> <p>Key insight: The GNN learns that certain network neighborhoods are \"failure-prone regions\" in feature space.</p>"},{"location":"ml/#2-lstm-long-short-term-memory","title":"2. LSTM (Long Short-Term Memory)","text":"<p>The LSTM detects temporal patterns and early warning trajectories.</p> <p>Intuition: Job failures often have precursors\u2014accelerating memory pressure, increasing I/O wait, declining CPU efficiency. The LSTM learns these temporal signatures.</p> <p>Architecture: <pre><code>Input: Time series of metrics (sequence_length \u00d7 features)\n  \u2502\n  \u25bc\nLSTM Layer (hidden_size=64)\n  \u2502\n  \u25bc\nLSTM Layer (hidden_size=32)\n  \u2502\n  \u25bc\nDense Layer (32 \u2192 16, ReLU)\n  \u2502\n  \u25bc\nDense Layer (16 \u2192 1, Sigmoid)\n  \u2502\n  \u25bc\nOutput: Failure probability\n</code></pre></p> <p>Sequence construction: For each job, we collect metrics at regular intervals (default: every 30 seconds) and form a time series.</p>"},{"location":"ml/#3-autoencoder-anomaly-detection","title":"3. Autoencoder (Anomaly Detection)","text":"<p>The autoencoder identifies jobs that deviate from normal behavior.</p> <p>Intuition: Train on successful jobs to learn \"normal\" patterns. Jobs that reconstruct poorly are anomalous\u2014and anomalies correlate with failures.</p> <p>Architecture: <pre><code>Input: Feature vector (17-dim)\n  \u2502\n  \u25bc\nEncoder:\n  Dense (17 \u2192 12, ReLU)\n  Dense (12 \u2192 8, ReLU)\n  Dense (8 \u2192 4, ReLU)  \u2190 Latent space\n  \u2502\n  \u25bc\nDecoder:\n  Dense (4 \u2192 8, ReLU)\n  Dense (8 \u2192 12, ReLU)\n  Dense (12 \u2192 17, Sigmoid)\n  \u2502\n  \u25bc\nReconstruction Error = MSE(input, output)\n  \u2502\n  \u25bc\nOutput: Anomaly score (higher = more anomalous)\n</code></pre></p> <p>Training: Only on COMPLETED (successful) jobs. The model learns what \"normal\" looks like.</p> <p>Inference: High reconstruction error suggests the job doesn't fit normal patterns.</p>"},{"location":"ml/#ensemble-combination","title":"Ensemble Combination","text":"<p>Individual model predictions are combined using weighted averaging:</p> \\[\\text{Risk Score} = w_1 \\cdot P_{GNN} + w_2 \\cdot P_{LSTM} + w_3 \\cdot S_{AE}\\] <p>Default weights:</p> Model Weight Rationale GNN 0.4 Strong structural signal LSTM 0.35 Good temporal patterns Autoencoder 0.25 Catches outliers <p>Weights are tunable via configuration or can be learned via cross-validation.</p>"},{"location":"ml/#training-pipeline","title":"Training Pipeline","text":""},{"location":"ml/#data-preparation","title":"Data Preparation","text":"<pre><code>nomade train --prepare\n</code></pre> <ol> <li>Extract completed jobs from database</li> <li>Compute feature vectors</li> <li>Label: COMPLETED=0, FAILED/TIMEOUT/CANCELLED=1</li> <li>Split: 80% train, 10% validation, 10% test</li> <li>Handle class imbalance (failures are rare):</li> <li>Oversample failures</li> <li>Or use class weights</li> </ol>"},{"location":"ml/#model-training","title":"Model Training","text":"<pre><code>nomade train\n</code></pre> <p>For each model:</p> <ol> <li>GNN: Train on similarity graph with node labels</li> <li>LSTM: Train on metric time series</li> <li>Autoencoder: Train reconstruction on successful jobs only</li> </ol> <p>Training outputs: <pre><code>~/.local/share/nomade/models/\n\u251c\u2500\u2500 gnn_model.pt\n\u251c\u2500\u2500 lstm_model.pt\n\u251c\u2500\u2500 autoencoder_model.pt\n\u2514\u2500\u2500 ensemble_weights.json\n</code></pre></p>"},{"location":"ml/#hyperparameters","title":"Hyperparameters","text":"Parameter Default Description <code>learning_rate</code> 0.001 Adam optimizer LR <code>epochs</code> 100 Training epochs <code>batch_size</code> 32 Mini-batch size <code>hidden_dim</code> 64 Hidden layer size <code>dropout</code> 0.2 Dropout rate <code>similarity_threshold</code> 0.7 For GNN graph"},{"location":"ml/#prediction-pipeline","title":"Prediction Pipeline","text":""},{"location":"ml/#real-time-scoring","title":"Real-Time Scoring","text":"<pre><code>nomade predict\n</code></pre> <p>For running jobs:</p> <ol> <li>Compute current feature vector</li> <li>Query similar historical jobs</li> <li>Run through ensemble</li> <li>Output risk score (0.0 - 1.0)</li> </ol>"},{"location":"ml/#risk-score-interpretation","title":"Risk Score Interpretation","text":"Score Level Recommended Action 0.0 - 0.3 Low No action needed 0.3 - 0.6 Moderate Monitor more frequently 0.6 - 0.8 High Alert user, suggest changes 0.8 - 1.0 Critical Immediate intervention"},{"location":"ml/#actionable-recommendations","title":"Actionable Recommendations","text":"<p>When risk is elevated, N\u00d8MADE provides specific recommendations based on which features contribute most: <pre><code>\u26a0\ufe0f Job 12345 has elevated failure risk (0.72)\n\nContributing factors:\n  \u2022 High NFS write ratio (0.89) \u2014 3x normal\n  \u2022 Low CPU efficiency (23%) \u2014 below 50% threshold\n\nRecommendations:\n  \u2022 Consider using local scratch: export TMPDIR=/scratch/$USER\n  \u2022 Reduce core count if not using parallelism\n</code></pre></p>"},{"location":"ml/#evaluation-metrics","title":"Evaluation Metrics","text":""},{"location":"ml/#classification-metrics","title":"Classification Metrics","text":"Metric Formula Target Precision TP / (TP + FP) &gt; 0.7 Recall TP / (TP + FN) &gt; 0.8 F1 Score 2 \u00d7 P \u00d7 R / (P + R) &gt; 0.75 AUC-ROC Area under ROC curve &gt; 0.85"},{"location":"ml/#operational-metrics","title":"Operational Metrics","text":"Metric Description Lead time How early before failure is risk elevated? False alarm rate Alerts that didn't result in failure Coverage % of failures that were predicted"},{"location":"ml/#cli-commands","title":"CLI Commands","text":"<pre><code># Train all models\nnomade train\n\n# Train specific model\nnomade train --model gnn\nnomade train --model lstm\nnomade train --model autoencoder\n\n# Run predictions\nnomade predict\n\n# Generate report\nnomade report\n\n# View model performance\nnomade ml status\n</code></pre>"},{"location":"ml/#configuration","title":"Configuration","text":"<p>In <code>nomade.toml</code>: <pre><code>[ml]\nenabled = true\nsimilarity_threshold = 0.7\nretrain_interval_days = 7\n\n[ml.ensemble]\ngnn_weight = 0.4\nlstm_weight = 0.35\nautoencoder_weight = 0.25\n\n[ml.alerts]\nhigh_risk_threshold = 0.7\nalert_on_prediction = true\n</code></pre></p>"},{"location":"network/","title":"Network Methodology","text":"<p>N\u00d8MADE's prediction engine uses similarity networks to identify job failure patterns. This approach draws inspiration from biogeographical network analysis.</p>"},{"location":"network/#theoretical-foundation","title":"Theoretical Foundation","text":""},{"location":"network/#from-biogeography-to-hpc","title":"From Biogeography to HPC","text":"<p>The methodology is inspired by Vilhena &amp; Antonelli (2015), who used network analysis to identify biogeographical regions from species distribution data. Just as biogeographical regions emerge from species patterns rather than being predefined, N\u00d8MADE allows job behavior patterns to emerge from metric data.</p> Biogeography Concept N\u00d8MADE Analog Species Jobs Geographic regions Compute resources (nodes, partitions) Emergent biomes Job behavior clusters Species ranges Resource usage patterns Transition zones Domain boundaries (CPU\u2194GPU, NFS\u2194local)"},{"location":"network/#why-cosine-similarity","title":"Why Cosine Similarity?","text":"<p>N\u00d8MADE uses cosine similarity on continuous feature vectors rather than Simpson similarity on categorical presence/absence data:</p> <ul> <li>Magnitude matters: CPU efficiency of 80% vs 20% is significant, not just \"used CPU\"</li> <li>Multi-dimensional: Jobs have 17+ continuous metrics</li> <li>Shape over scale: Cosine similarity captures resource profiles, not absolute consumption</li> </ul> <p>A job requesting 64GB with 50% utilization has a similar profile to one requesting 8GB with 50% utilization\u2014both represent reasonable memory sizing\u2014even though absolute consumption differs by 8x.</p>"},{"location":"network/#network-construction","title":"Network Construction","text":""},{"location":"network/#step-1-feature-vector-extraction","title":"Step 1: Feature Vector Extraction","text":"<p>Each completed job produces a 17-dimensional feature vector: <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Job Feature Vector                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 CPU Metrics          \u2502 cpu_efficiency, cores_requested,    \u2502\n\u2502                      \u2502 cpu_time_used, avg_cpu_percent      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Memory Metrics       \u2502 mem_efficiency, mem_requested_gb,   \u2502\n\u2502                      \u2502 peak_mem_gb, avg_mem_percent        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 I/O Metrics          \u2502 nfs_read_gb, nfs_write_gb,          \u2502\n\u2502                      \u2502 local_read_gb, local_write_gb,      \u2502\n\u2502                      \u2502 nfs_ratio, io_wait_percent          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Time Metrics         \u2502 runtime_seconds, requested_seconds, \u2502\n\u2502                      \u2502 time_efficiency                     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 GPU Metrics          \u2502 gpu_utilization, gpu_mem_percent    \u2502\n\u2502 (if applicable)      \u2502                                     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"network/#step-2-z-score-normalization","title":"Step 2: Z-Score Normalization","text":"<p>Features are normalized to zero mean, unit variance:</p> \\[z_i = \\frac{x_i - \\mu_i}{\\sigma_i}\\] <p>This ensures all dimensions contribute equally to similarity calculations.</p>"},{"location":"network/#step-3-cosine-similarity-matrix","title":"Step 3: Cosine Similarity Matrix","text":"<p>For jobs \\(a\\) and \\(b\\) with feature vectors \\(\\vec{a}\\) and \\(\\vec{b}\\):</p> \\[\\text{similarity}(a, b) = \\frac{\\vec{a} \\cdot \\vec{b}}{|\\vec{a}| \\cdot |\\vec{b}|}\\] <p>Values range from -1 (opposite profiles) to +1 (identical profiles).</p>"},{"location":"network/#step-4-edge-creation","title":"Step 4: Edge Creation","text":"<p>Edges connect jobs with similarity \u2265 threshold (default: 0.7): <pre><code>if cosine_similarity(job_a, job_b) &gt;= 0.7:\n    network.add_edge(job_a, job_b)\n</code></pre></p> <p>Threshold trade-offs:</p> Threshold Network Density Clusters Use Case 0.9+ Sparse Tight, specific Anomaly detection 0.7 (default) Moderate Balanced General prediction 0.5 Dense Broad patterns Exploratory analysis"},{"location":"network/#step-5-community-detection","title":"Step 5: Community Detection","text":"<p>Connected components and modularity-based clustering identify job communities\u2014groups with similar resource profiles.</p>"},{"location":"network/#bipartite-network-approach","title":"Bipartite Network Approach","text":"<p>For advanced analysis, N\u00d8MADE implements Vilhena &amp; Antonelli's bipartite approach: <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    Jobs      \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502 Resource Bins\u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 job_1001     \u2502\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u25b6\u2502 cpu_high     \u2502\n\u2502 job_1002     \u2502\u2500\u2500\u2500\u2500\u2524     \u2502 cpu_low      \u2502\n\u2502 job_1003     \u2502\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u25b6\u2502 mem_high     \u2502\n\u2502 job_1004     \u2502\u2500\u2500\u2500\u2500\u2524     \u2502 mem_low      \u2502\n\u2502 ...          \u2502\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u25b6\u2502 io_nfs_heavy \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p> <ol> <li>Discretize features into bins (e.g., cpu_high, cpu_low)</li> <li>Create bipartite graph: jobs connected to their resource bins</li> <li>Project onto job-job network: jobs sharing bins are connected</li> <li>Weight by overlap: more shared bins = stronger connection</li> </ol> <p>This approach:</p> <ul> <li>Treats each resource bin as a \"site\" (biogeography analogy)</li> <li>Reveals emergent behavioral regions</li> <li>Handles missing data gracefully</li> </ul>"},{"location":"network/#network-metrics","title":"Network Metrics","text":""},{"location":"network/#assortativity","title":"Assortativity","text":"<p>Measures whether failed jobs cluster together:</p> \\[r = \\frac{\\sum_{ij}(A_{ij} - k_i k_j / 2m) \\delta(c_i, c_j)}{2m - \\sum_{ij}(k_i k_j / 2m) \\delta(c_i, c_j)}\\] <ul> <li>Positive: Failed jobs connect to failed jobs (pattern exists)</li> <li>Zero: Random mixing (no predictive signal)</li> <li>Negative: Failed jobs connect to successful jobs (unusual)</li> </ul>"},{"location":"network/#clustering-coefficient","title":"Clustering Coefficient","text":"<p>Local clustering indicates behavioral cohesion:</p> \\[C_i = \\frac{2 |\\{e_{jk}\\}|}{k_i(k_i - 1)}\\] <p>High clustering = consistent failure patterns.</p>"},{"location":"network/#statistical-significance","title":"Statistical Significance","text":"<p>N\u00d8MADE tests whether observed patterns exceed random chance using permutation tests:</p> <ol> <li>Shuffle failure labels 1000 times</li> <li>Compute metric for each shuffle</li> <li>Calculate z-score: \\(z = (observed - \\mu_{null}) / \\sigma_{null}\\)</li> <li>Report significance if \\(|z| &gt; 2\\)</li> </ol>"},{"location":"network/#visualization","title":"Visualization","text":"<p>The dashboard provides a 3D force-directed network visualization:</p> <ul> <li>Node color: Green (healthy) to Red (failed)</li> <li>Node position: Fruchterman-Reingold layout</li> <li>Axes: NFS ratio, local I/O, I/O wait</li> <li>Regions: \"Safe zone\" vs \"danger zone\" emerge from data</li> </ul>"},{"location":"network/#references","title":"References","text":"<p>Vilhena, D.A., Antonelli, A. (2015). A network approach for identifying and delimiting biogeographical regions. Nature Communications 6:6848. DOI: 10.1038/ncomms7848</p>"},{"location":"proficiency/","title":"Proficiency Scoring","text":"<p>N\u00d8MADE's Educational Analytics module tracks computational proficiency development through per-job behavioral fingerprints.</p>"},{"location":"proficiency/#philosophy","title":"Philosophy","text":"<p>Traditional HPC monitoring answers: \"Did the job run?\"</p> <p>N\u00d8MADE Edu answers: \"Did the user learn to use HPC effectively?\"</p> <p>This shift enables:</p> <ul> <li>Instructors to measure learning outcomes, not just resource consumption</li> <li>Mentors to identify specific skill gaps in research trainees</li> <li>Users to self-assess and improve their HPC practices</li> <li>Institutions to evaluate training program effectiveness</li> </ul>"},{"location":"proficiency/#the-five-dimensions","title":"The Five Dimensions","text":"<p>Every completed job is scored across five proficiency dimensions: <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              Proficiency Fingerprint                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                            \u2502\n\u2502  CPU Efficiency      \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591  78%   Good                \u2502\n\u2502  Memory Efficiency   \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591  89%   Excellent           \u2502\n\u2502  Time Estimation     \u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591  62%   Developing          \u2502\n\u2502  I/O Awareness       \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591  91%   Excellent           \u2502\n\u2502  GPU Utilization     \u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591\u2591  34%   Needs Work          \u2502\n\u2502                                                            \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500     \u2502\n\u2502  Overall Score       \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591  71%   Good                \u2502\n\u2502                                                            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"proficiency/#1-cpu-efficiency","title":"1. CPU Efficiency","text":"<p>What it measures: How well did the user utilize requested CPU cores?</p> <p>Formula: $\\(\\text{CPU Score} = \\min\\left(100, \\frac{\\text{CPU Time Used}}{\\text{Cores} \\times \\text{Walltime}} \\times 100\\right)\\)$</p> <p>Scoring rubric:</p> Efficiency Score Level Interpretation \u2265 80% 85-100 Excellent Efficient parallelization 50-79% 65-84 Good Reasonable usage 25-49% 40-64 Developing Some waste, learning &lt; 25% 0-39 Needs Work Significant over-allocation <p>Common issues:</p> <ul> <li>Requesting 16 cores for single-threaded code</li> <li>I/O-bound jobs with idle CPUs</li> <li>Poor parallel scaling</li> </ul> <p>Recommendations generated: <pre><code>CPU Efficiency: Very low CPU utilization at 21% \u2014 requested 4 \ncores but used ~1. This wastes resources and may delay other \nusers' jobs.\n\nTry: #SBATCH --ntasks=1\n     If your code is single-threaded, request 1 core.\n</code></pre></p>"},{"location":"proficiency/#2-memory-efficiency","title":"2. Memory Efficiency","text":"<p>What it measures: How well did the user size their memory request?</p> <p>Formula: $\\(\\text{Memory Score} = \\begin{cases} 100 - (100 - \\text{Utilization}) \\times 0.5 &amp; \\text{if utilization} \\geq 50\\% \\\\ \\text{Utilization} \\times 1.5 &amp; \\text{if utilization} &lt; 50\\% \\end{cases}\\)$</p> <p>The asymmetric formula penalizes under-utilization more harshly than slight over-utilization (better to have headroom than OOM kills).</p> <p>Scoring rubric:</p> Utilization Score Level Interpretation 70-95% 85-100 Excellent Well-sized 50-69% 65-84 Good Acceptable headroom 30-49% 40-64 Developing Over-allocated &lt; 30% 0-39 Needs Work Significant waste <p>Common issues:</p> <ul> <li>Requesting 64GB when job uses 2GB</li> <li>Copy-pasting scripts without adjusting memory</li> <li>Not profiling memory requirements</li> </ul>"},{"location":"proficiency/#3-time-estimation","title":"3. Time Estimation","text":"<p>What it measures: How accurately did the user estimate walltime?</p> <p>Formula: $\\(\\text{Time Score} = \\begin{cases} 95 + 5 \\times (1 - \\frac{\\text{Runtime}}{\\text{Requested}}) &amp; \\text{if ratio} \\geq 0.7 \\\\ 70 \\times \\frac{\\text{Runtime}}{\\text{Requested}} &amp; \\text{if ratio} &lt; 0.7 \\end{cases}\\)$</p> <p>Using close to requested time (without exceeding) is optimal.</p> <p>Scoring rubric:</p> Runtime/Requested Score Level Interpretation 70-100% 85-100 Excellent Accurate estimation 40-69% 65-84 Good Conservative but reasonable 20-39% 40-64 Developing Significant overestimation &lt; 20% 0-39 Needs Work Gross overestimation <p>Why it matters:</p> <ul> <li>Backfill scheduling depends on accurate time estimates</li> <li>Over-requesting blocks resources from others</li> <li>Under-requesting causes job kills</li> </ul>"},{"location":"proficiency/#4-io-awareness","title":"4. I/O Awareness","text":"<p>What it measures: Did the user choose appropriate storage for their workload?</p> <p>Formula: $\\(\\text{I/O Score} = 100 - (\\text{NFS Ratio} \\times 50) - (\\text{IO Wait} \\times 2)\\)$</p> <p>Where: - NFS Ratio = NFS writes / Total writes - IO Wait = percentage of time waiting on I/O</p> <p>Scoring rubric:</p> NFS Ratio IO Wait Score Level &lt; 20% &lt; 5% 85-100 Excellent 20-50% 5-15% 65-84 Good 50-80% 15-30% 40-64 Developing &gt; 80% &gt; 30% 0-39 Needs Work <p>Common issues:</p> <ul> <li>Writing temp files to NFS instead of local scratch</li> <li>Not using <code>$TMPDIR</code> or <code>/scratch</code></li> <li>Reading input files repeatedly from network storage</li> </ul> <p>Recommendations generated: <pre><code>I/O Awareness: High NFS write ratio (78%) causing I/O wait. \nJobs with this pattern have 3x higher failure rates.\n\nTry: export TMPDIR=/scratch/$USER/$SLURM_JOB_ID\n     Write temporary files to local scratch, copy results \n     back at job end.\n</code></pre></p>"},{"location":"proficiency/#5-gpu-utilization","title":"5. GPU Utilization","text":"<p>What it measures: Did the user effectively utilize requested GPUs?</p> <p>Formula: $\\(\\text{GPU Score} = \\frac{\\text{GPU Utilization} + \\text{GPU Memory Utilization}}{2}\\)$</p> <p>Scoring rubric:</p> GPU Util Score Level Interpretation \u2265 70% 85-100 Excellent Efficient GPU usage 40-69% 65-84 Good Acceptable 20-39% 40-64 Developing Under-utilizing expensive resource &lt; 20% 0-39 Needs Work GPU mostly idle <p>Applicability: Only scored if job requested GPUs. Non-GPU jobs show \"N/A\".</p> <p>Common issues:</p> <ul> <li>CPU preprocessing starving GPU</li> <li>Small batch sizes</li> <li>Requesting GPU for CPU-only code</li> </ul>"},{"location":"proficiency/#proficiency-levels","title":"Proficiency Levels","text":"<p>Scores map to four proficiency levels:</p> Score Range Level Description 85-100 Excellent Demonstrates strong HPC understanding 65-84 Good Reasonable usage with minor inefficiencies 40-64 Developing Learning, with clear room for improvement 0-39 Needs Work Significant resource waste or misconfiguration"},{"location":"proficiency/#overall-score","title":"Overall Score","text":"<p>The overall score is a weighted average:</p> \\[\\text{Overall} = \\frac{\\sum_{d \\in \\text{applicable}} w_d \\times s_d}{\\sum_{d \\in \\text{applicable}} w_d}\\] <p>Default weights:</p> Dimension Weight Rationale CPU 1.0 Core resource Memory 1.0 Core resource Time 0.8 Important for scheduling I/O 0.8 Important for cluster health GPU 1.0 Expensive resource (when applicable)"},{"location":"proficiency/#trajectory-tracking","title":"Trajectory Tracking","text":"<p>Beyond single jobs, N\u00d8MADE tracks proficiency development over time: <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502           Proficiency Trajectory \u2014 alice                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Jobs analyzed: 173    Period: 2026-01-15 \u2192 2026-02-15     \u2502\n\u2502 Trend: Improving                                           \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Score Progression                                          \u2502\n\u2502                                                            \u2502\n\u2502   2026-01-15    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591   78.6%  (21 jobs)             \u2502\n\u2502   2026-02-01    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591   82.3%  (52 jobs)             \u2502\n\u2502   2026-02-15    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591   86.1%  (100 jobs)            \u2502\n\u2502                                                            \u2502\n\u2502 Dimension Changes                                          \u2502\n\u2502                                                            \u2502\n\u2502   CPU Efficiency      48.3% \u2192 71.2%   \u2191 +22.9%            \u2502\n\u2502   Memory Efficiency   84.0% \u2192 89.9%   \u2191 +5.9%             \u2502\n\u2502   Time Estimation     72.1% \u2192 85.4%   \u2191 +13.3%            \u2502\n\u2502   I/O Awareness       81.5% \u2192 88.2%   \u2191 +6.7%             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p> <p>Trend classification:</p> Trend Criteria Improving Recent average &gt; Historical average + 5% Stable Within \u00b15% Declining Recent average &lt; Historical average - 5%"},{"location":"proficiency/#group-reports","title":"Group Reports","text":"<p>Aggregate proficiency across course sections or research groups: <pre><code>nomade edu report cs301\n</code></pre> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502           N\u00d8MADE Group Report \u2014 cs301                      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Members: 24    Jobs: 1,847    Period: 2026-01-15 \u2192 02-15  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Key Insight                                                \u2502\n\u2502   18/24 students improved overall proficiency              \u2502\n\u2502                                                            \u2502\n\u2502 Group Proficiency                                          \u2502\n\u2502   Memory Efficiency    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591   92.1%  \u2192 +3.2%      \u2502\n\u2502   Time Estimation      \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591   84.7%  \u2192 +8.1%      \u2502\n\u2502   I/O Awareness        \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591   79.3%  \u2192 +5.4%      \u2502\n\u2502   CPU Efficiency       \u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591\u2591\u2591\u2591\u2591   58.2%  \u2192 +12.1%     \u2502\n\u2502                                                            \u2502\n\u2502 Weakest area: CPU    |    Strongest: Memory               \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Student Breakdown                                          \u2502\n\u2502   Improving:  18                                           \u2502\n\u2502   Stable:      4                                           \u2502\n\u2502   Declining:   2                                           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p> <p>Use cases:</p> <ul> <li>Instructors: Identify which concepts need more coverage</li> <li>TA/Mentors: Find students needing individual help</li> <li>Administrators: Evaluate workshop effectiveness</li> <li>Researchers: Track new lab member onboarding</li> </ul>"},{"location":"proficiency/#database-storage","title":"Database Storage","text":"<p>Proficiency scores are persisted for longitudinal analysis: <pre><code>CREATE TABLE proficiency_scores (\n    id INTEGER PRIMARY KEY,\n    timestamp DATETIME,\n    job_id TEXT NOT NULL,\n    user_name TEXT NOT NULL,\n    cluster TEXT,\n\n    -- Dimension scores\n    cpu_score REAL,\n    cpu_level TEXT,\n    memory_score REAL,\n    memory_level TEXT,\n    time_score REAL,\n    time_level TEXT,\n    io_score REAL,\n    io_level TEXT,\n    gpu_score REAL,\n    gpu_level TEXT,\n    gpu_applicable INTEGER,\n\n    -- Overall\n    overall_score REAL,\n    overall_level TEXT,\n\n    -- Recommendations\n    needs_work TEXT,  -- JSON array of dimension names\n    strengths TEXT,   -- JSON array of dimension names\n\n    UNIQUE(job_id)\n);\n</code></pre></p>"},{"location":"proficiency/#cli-commands","title":"CLI Commands","text":"<pre><code># Explain a single job\nnomade edu explain &lt;job_id&gt;\nnomade edu explain &lt;job_id&gt; --json\nnomade edu explain &lt;job_id&gt; --no-progress\n\n# User trajectory\nnomade edu trajectory &lt;username&gt;\nnomade edu trajectory &lt;username&gt; --days 30\nnomade edu trajectory &lt;username&gt; --json\n\n# Group report\nnomade edu report &lt;group_name&gt;\nnomade edu report &lt;group_name&gt; --days 90\nnomade edu report &lt;group_name&gt; --json\n</code></pre>"},{"location":"proficiency/#integration-with-slurm","title":"Integration with SLURM","text":"<p>For automatic scoring, add to SLURM epilog: <pre><code>#!/bin/bash\n# /etc/slurm/epilog.d/nomade-edu.sh\n\nnomade edu explain $SLURM_JOB_ID --json &gt;&gt; /var/log/nomade/edu.log 2&gt;&amp;1\n</code></pre></p> <p>Users can then view their proficiency in the dashboard or via CLI.</p>"},{"location":"quickstart/","title":"Quick Start","text":""},{"location":"quickstart/#try-without-hpc","title":"Try Without HPC","text":"<pre><code>pip install nomade-hpc\nnomade demo\n</code></pre> <p>This launches a dashboard at http://localhost:8050 with synthetic data.</p>"},{"location":"quickstart/#production-setup","title":"Production Setup","text":""},{"location":"quickstart/#1-install","title":"1. Install","text":"<pre><code>pip install nomade-hpc\n</code></pre>"},{"location":"quickstart/#2-configure","title":"2. Configure","text":"<pre><code>nomade init\n</code></pre> <p>Follow the wizard to configure your cluster(s).</p>"},{"location":"quickstart/#3-collect-data","title":"3. Collect Data","text":"<pre><code>nomade collect\n</code></pre> <p>Leave running (or set up as systemd service).</p>"},{"location":"quickstart/#4-view-dashboard","title":"4. View Dashboard","text":"<pre><code>nomade dashboard\n</code></pre> <p>Open http://localhost:8050</p>"},{"location":"quickstart/#first-commands-to-try","title":"First Commands to Try","text":"<pre><code># System status\nnomade status\n\n# Disk usage trends\nnomade disk /home\n\n# Recent jobs\nnomade jobs --user $USER\n\n# Educational analytics (if you have job data)\nnomade edu explain &lt;job_id&gt;\n</code></pre>"},{"location":"quickstart/#next-steps","title":"Next Steps","text":"<ul> <li>Configuration \u2014 Customize collectors and alerts</li> <li>Dashboard \u2014 Navigate the web interface</li> <li>Educational Analytics \u2014 Track proficiency development</li> <li>CLI Reference \u2014 All available commands</li> </ul>"},{"location":"system-install/","title":"System Install","text":"<p>This guide covers deploying N\u00d8MADE system-wide for production HPC environments.</p>"},{"location":"system-install/#overview","title":"Overview","text":"<p>System install differs from user install in several ways:</p> Aspect User Install System Install Config location <code>~/.config/nomade/</code> <code>/etc/nomade/</code> Data location <code>~/.local/share/nomade/</code> <code>/var/lib/nomade/</code> Log location <code>~/.local/share/nomade/logs/</code> <code>/var/log/nomade/</code> Permissions User only Controlled by file permissions Service Manual or user systemd System systemd unit Dashboard access localhost only Configurable (proxy recommended)"},{"location":"system-install/#installation","title":"Installation","text":""},{"location":"system-install/#prerequisites","title":"Prerequisites","text":"<pre><code># Install as root or with sudo\nsudo pip install nomade-hpc\n\n# Or system-wide from source\nsudo pip install /path/to/nomade/\n</code></pre>"},{"location":"system-install/#initialize-system-configuration","title":"Initialize System Configuration","text":"<pre><code>sudo nomade init --system\n</code></pre> <p>This creates:</p> Path Purpose Permissions <code>/etc/nomade/</code> Configuration directory <code>root:root 755</code> <code>/etc/nomade/nomade.toml</code> Main configuration <code>root:root 644</code> <code>/var/lib/nomade/</code> Data directory <code>root:nomade 750</code> <code>/var/lib/nomade/nomade.db</code> SQLite database <code>root:nomade 660</code> <code>/var/log/nomade/</code> Log directory <code>root:nomade 750</code>"},{"location":"system-install/#required-permissions","title":"Required Permissions","text":"<p>Running as root: Full access to all paths.</p> <p>Running as service user (recommended): <pre><code># Create nomade group\nsudo groupadd nomade\n\n# Create service user\nsudo useradd -r -g nomade -d /var/lib/nomade -s /sbin/nologin nomade\n\n# Set ownership\nsudo chown -R nomade:nomade /var/lib/nomade\nsudo chown -R nomade:nomade /var/log/nomade\nsudo chown root:nomade /etc/nomade/nomade.toml\nsudo chmod 640 /etc/nomade/nomade.toml\n</code></pre></p> <p>Wheel group access (for admin users): <pre><code># Allow wheel group to read config\nsudo chown root:wheel /etc/nomade/nomade.toml\nsudo chmod 640 /etc/nomade/nomade.toml\n\n# Allow wheel group to read database\nsudo chown nomade:wheel /var/lib/nomade/nomade.db\nsudo chmod 660 /var/lib/nomade/nomade.db\n</code></pre></p>"},{"location":"system-install/#files-modifiedaccessed","title":"Files Modified/Accessed","text":""},{"location":"system-install/#configuration-files","title":"Configuration Files","text":"File Read/Write Purpose <code>/etc/nomade/nomade.toml</code> R Main configuration <code>/etc/nomade/clusters/*.toml</code> R Per-cluster configs (optional)"},{"location":"system-install/#data-files","title":"Data Files","text":"File Read/Write Purpose <code>/var/lib/nomade/nomade.db</code> RW SQLite database <code>/var/lib/nomade/models/</code> RW ML model files <code>/var/lib/nomade/cache/</code> RW Temporary cache"},{"location":"system-install/#log-files","title":"Log Files","text":"File Read/Write Purpose <code>/var/log/nomade/nomade.log</code> W Main application log <code>/var/log/nomade/collector.log</code> W Collector logs <code>/var/log/nomade/alerts.log</code> W Alert dispatch logs"},{"location":"system-install/#system-files-read","title":"System Files Read","text":"File Purpose <code>/proc/*/io</code> Per-process I/O stats <code>/proc/meminfo</code> Memory information <code>/proc/loadavg</code> System load <code>/sys/class/thermal/</code> Temperature sensors"},{"location":"system-install/#external-commands-executed","title":"External Commands Executed","text":"Command Package Purpose <code>iostat</code> sysstat Disk I/O metrics <code>mpstat</code> sysstat CPU metrics <code>vmstat</code> procps Memory/swap metrics <code>df</code> coreutils Filesystem usage <code>nvidia-smi</code> nvidia-driver GPU metrics (optional) <code>nfsiostat</code> nfs-utils NFS metrics (optional) <code>squeue</code> slurm Job queue (optional) <code>sinfo</code> slurm Node info (optional) <code>sacct</code> slurm Job accounting (optional)"},{"location":"system-install/#systemd-service","title":"Systemd Service","text":""},{"location":"system-install/#create-service-unit","title":"Create Service Unit","text":"<pre><code>sudo cat &gt; /etc/systemd/system/nomade-collector.service &lt;&lt; 'UNIT'\n[Unit]\nDescription=N\u00d8MADE HPC Monitoring Collector\nAfter=network.target slurmd.service\n\n[Service]\nType=simple\nUser=nomade\nGroup=nomade\nExecStart=/usr/local/bin/nomade collect\nRestart=always\nRestartSec=30\n\n# Security hardening\nNoNewPrivileges=true\nProtectSystem=strict\nProtectHome=true\nReadWritePaths=/var/lib/nomade /var/log/nomade\nPrivateTmp=true\n\n[Install]\nWantedBy=multi-user.target\nUNIT\n</code></pre>"},{"location":"system-install/#enable-and-start","title":"Enable and Start","text":"<pre><code>sudo systemctl daemon-reload\nsudo systemctl enable nomade-collector\nsudo systemctl start nomade-collector\nsudo systemctl status nomade-collector\n</code></pre>"},{"location":"system-install/#dashboard-service-optional","title":"Dashboard Service (Optional)","text":"<pre><code>sudo cat &gt; /etc/systemd/system/nomade-dashboard.service &lt;&lt; 'UNIT'\n[Unit]\nDescription=N\u00d8MADE Dashboard\nAfter=network.target nomade-collector.service\n\n[Service]\nType=simple\nUser=nomade\nGroup=nomade\nExecStart=/usr/local/bin/nomade dashboard --host 127.0.0.1 --port 8050\nRestart=always\nRestartSec=10\n\n[Install]\nWantedBy=multi-user.target\nUNIT\n</code></pre>"},{"location":"system-install/#web-dashboard-access","title":"Web Dashboard Access","text":""},{"location":"system-install/#localhost-only-default","title":"Localhost Only (Default)","text":"<p>Dashboard binds to <code>127.0.0.1:8050</code> by default. Access via SSH tunnel: <pre><code># On your local machine\nssh -L 8050:localhost:8050 user@hpc-head-node\n\n# Then open http://localhost:8050 in browser\n</code></pre></p>"},{"location":"system-install/#reverse-proxy-recommended-for-remote-access","title":"Reverse Proxy (Recommended for Remote Access)","text":"<p>Using Apache: <pre><code># /etc/httpd/conf.d/nomade.conf\n&lt;VirtualHost *:443&gt;\n    ServerName hpc.example.edu\n\n    SSLEngine on\n    SSLCertificateFile /etc/pki/tls/certs/server.crt\n    SSLCertificateKeyFile /etc/pki/tls/private/server.key\n\n    &lt;Location /nomade&gt;\n        ProxyPass http://127.0.0.1:8050/\n        ProxyPassReverse http://127.0.0.1:8050/\n\n        # Require authentication\n        AuthType Basic\n        AuthName \"N\u00d8MADE Dashboard\"\n        AuthUserFile /etc/httpd/.htpasswd\n        Require valid-user\n    &lt;/Location&gt;\n&lt;/VirtualHost&gt;\n</code></pre></p> <p>Using nginx: <pre><code># /etc/nginx/conf.d/nomade.conf\nserver {\n    listen 443 ssl;\n    server_name hpc.example.edu;\n\n    ssl_certificate /etc/ssl/certs/server.crt;\n    ssl_certificate_key /etc/ssl/private/server.key;\n\n    location /nomade/ {\n        proxy_pass http://127.0.0.1:8050/;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n\n        # WebSocket support (for live updates)\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection \"upgrade\";\n\n        # Authentication\n        auth_basic \"N\u00d8MADE Dashboard\";\n        auth_basic_user_file /etc/nginx/.htpasswd;\n    }\n}\n</code></pre></p>"},{"location":"system-install/#slurm-integration","title":"SLURM Integration","text":""},{"location":"system-install/#prologepilog-hooks","title":"Prolog/Epilog Hooks","text":"<p>For per-job metrics collection: <pre><code># Copy hook scripts\nsudo cp /path/to/nomade/scripts/prolog.sh /etc/slurm/prolog.d/nomade.sh\nsudo cp /path/to/nomade/scripts/epilog.sh /etc/slurm/epilog.d/nomade.sh\n\n# Make executable\nsudo chmod +x /etc/slurm/prolog.d/nomade.sh\nsudo chmod +x /etc/slurm/epilog.d/nomade.sh\n\n# Restart SLURM controller\nsudo systemctl restart slurmctld\n</code></pre></p>"},{"location":"system-install/#prolog-script","title":"Prolog Script","text":"<pre><code>#!/bin/bash\n# /etc/slurm/prolog.d/nomade.sh\n/usr/local/bin/nomade job-start $SLURM_JOB_ID 2&gt;/dev/null || true\n</code></pre>"},{"location":"system-install/#epilog-script","title":"Epilog Script","text":"<pre><code>#!/bin/bash\n# /etc/slurm/epilog.d/nomade.sh\n/usr/local/bin/nomade job-end $SLURM_JOB_ID 2&gt;/dev/null || true\n</code></pre>"},{"location":"system-install/#multi-cluster-setup","title":"Multi-Cluster Setup","text":"<p>For monitoring multiple clusters from one head node: <pre><code># /etc/nomade/nomade.toml\n\n[clusters.spydur]\nname = \"Spydur\"\ntype = \"slurm\"\nssh_host = \"spydur-head\"\npartitions = [\"compute\", \"gpu\", \"highmem\"]\n\n[clusters.arachne]\nname = \"Arachne\"\ntype = \"slurm\"\nssh_host = \"arachne-head\"\npartitions = [\"standard\", \"large\"]\n</code></pre></p>"},{"location":"system-install/#security-considerations","title":"Security Considerations","text":""},{"location":"system-install/#database-access","title":"Database Access","text":"<p>The SQLite database contains job metadata including usernames. Restrict access: <pre><code># Only nomade user and wheel group can read\nsudo chmod 660 /var/lib/nomade/nomade.db\nsudo chown nomade:wheel /var/lib/nomade/nomade.db\n</code></pre></p>"},{"location":"system-install/#configuration-secrets","title":"Configuration Secrets","text":"<p>If using Slack/email alerts, config contains credentials: <pre><code># Restrict config file\nsudo chmod 640 /etc/nomade/nomade.toml\nsudo chown root:nomade /etc/nomade/nomade.toml\n</code></pre></p>"},{"location":"system-install/#dashboard-authentication","title":"Dashboard Authentication","text":"<p>Always use authentication for remote dashboard access. Never expose port 8050 directly to the network.</p>"},{"location":"system-install/#troubleshooting","title":"Troubleshooting","text":""},{"location":"system-install/#permission-denied","title":"Permission Denied","text":"<pre><code>PermissionError: [Errno 13] Permission denied: '/var/lib/nomade/nomade.db'\n</code></pre> <p>Solution: Check ownership and permissions: <pre><code>sudo chown nomade:nomade /var/lib/nomade/nomade.db\nsudo chmod 660 /var/lib/nomade/nomade.db\n</code></pre></p>"},{"location":"system-install/#collector-not-starting","title":"Collector Not Starting","text":"<p>Check systemd logs: <pre><code>sudo journalctl -u nomade-collector -f\n</code></pre></p>"},{"location":"system-install/#slurm-commands-failing","title":"SLURM Commands Failing","text":"<p>Ensure the nomade user can run SLURM commands: <pre><code>sudo -u nomade squeue\n</code></pre></p> <p>May need to add nomade user to appropriate groups or configure SLURM ACLs.</p>"}]}