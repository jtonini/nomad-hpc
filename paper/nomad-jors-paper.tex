\documentclass[11pt,a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage[margin=2.5cm]{geometry}
\usepackage{parskip}

\title{Software paper for submission to the\\Journal of Open Research Software}
\author{}
\date{}

\begin{document}

\maketitle

\section*{(1) Overview}

\subsection*{Title}
NØMAD: Lightweight HPC Monitoring and Diagnostics with Machine Learning-Based Failure Prediction

\subsection*{Paper Authors}
\begin{enumerate}
\item Tonini, João Filipe Riva (corresponding author)
\end{enumerate}

\subsection*{Paper Author Roles and Affiliations}
\begin{enumerate}
\item Academic Research Computing, University of Richmond, Richmond, VA 23173, USA.\\
Email: jtonini@richmond.edu\\
ORCID: 0000-0002-4730-3805
\end{enumerate}

\subsection*{Abstract}
NØMAD (NOde Monitoring And Diagnostics) is a lightweight monitoring and predictive analytics tool designed for computing infrastructure that requires minimal deployment overhead. At its core, metric collectors scheduled via systemd timers gather system metrics---disk, CPU, memory, I/O, and GPU utilization---from standard Linux tools, storing everything in a single SQLite database. When SLURM is available, these collectors extend to capture job-level analytics from scheduler commands and per-process I/O statistics, enabling deeper insight into workload behavior. The system employs machine learning models to predict job failures before they occur, while a data readiness estimator helps administrators determine when sufficient historical data has been collected for reliable predictions. Beyond prediction, diagnostic tools provide targeted analysis of network performance, storage health, and node-level bottlenecks. A key innovation is modeling jobs as nodes in a similarity network, where edges connect jobs with comparable resource usage patterns; because jobs with similar characteristics tend to share similar outcomes, the network structure reveals failure-prone regions in the feature space. The tool includes a real-time web dashboard for visualization and supports alerts via email, Slack, or webhooks. By requiring no external databases or complex infrastructure, NØMAD is particularly well-suited for small-to-medium HPC centers and research groups seeking sophisticated monitoring without enterprise-scale overhead.

\subsection*{Keywords}
HPC; high-performance computing; monitoring; machine learning; SLURM; predictive analytics; failure prediction

\subsection*{Introduction}

HPC administrators face a persistent challenge: detecting job failures before they impact researchers. While traditional monitoring tools offer valuable capabilities, they have evolved along two separate paths---enterprise IT solutions and HPC-specific tools---neither of which fully addresses this need.

Enterprise monitoring solutions like Prometheus \cite{prometheus},
Grafana \cite{grafana}, and Nagios \cite{nagios} provide mature, feature-rich platforms but require
significant infrastructure---database servers, message queues, and
dedicated hardware---that may be impractical for small-to-medium HPC
centers. These tools target general IT workloads and lack native
understanding of HPC concepts such as job schedulers, batch queues, and
compute allocations.
HPC-specific tools address this domain gap but introduce their own complexity. TACC Stats \cite{tacc}, for example, provides comprehensive hardware counter data and correlates system metrics with job performance, enabling detailed post-hoc analysis of application behavior. At the institutional scale, XDMoD \cite{xdmod} offers sophisticated job accounting and resource utilization reporting, though its deployment requires multiple database backends and web services. For large-scale continuous monitoring, the Lightweight Distributed Metric Service (LDMS) \cite{ldms} achieves impressive scalability through a distributed architecture. What these tools share, despite their different approaches, is an emphasis on retrospective analysis---understanding what happened after a failure---rather than real-time prediction of failures before they occur.

A complementary approach treats failure prediction as a pattern recognition problem. Jobs that fail often share common characteristics:
excessive NFS writes, memory pressure, or inefficient CPU utilization.
Machine learning methods have been applied to HPC failure prediction
\cite{mlhpc}, typically using classification models trained on job
features. However, these approaches often treat jobs as independent
observations, ignoring the structural relationships between jobs with
similar resource profiles.

NØMAD addresses these gaps by combining zero-infrastructure deployment
with network-based failure prediction. The key insight is that jobs with
similar resource usage patterns tend to experience similar outcomes.
Rather than treating each job independently, NØMAD models jobs as nodes
in a similarity network where edges connect jobs with comparable
behavioral fingerprints. This network structure reveals failure-prone
regions in the feature space---clusters of jobs that share
characteristics associated with poor outcomes---enabling both risk
assessment for individual jobs and actionable recommendations for users.

The choice of similarity metric is consequential for network topology.
NØMAD uses cosine similarity on Z-score normalized feature vectors,
which emphasizes the \emph{shape} of resource usage profiles rather than
absolute magnitudes. A job requesting 64GB of memory with 50\%
utilization has a similar profile to one requesting 8GB with 50\%
utilization---both represent reasonable memory sizing---even though
their absolute consumption differs by an order of magnitude. This
approach draws inspiration from network-based methods in biogeography,
where similarity metrics identify emergent regions from species
distribution patterns \cite{vilhena}. Just as biogeographical networks
reveal ecological boundaries from observational data without predefined
regions, job similarity networks reveal behavioral boundaries between
successful and failing workloads without predefined failure categories.
The similarity threshold (default $\geq 0.7$) controls network density:
higher thresholds create sparser networks with tighter clusters, while
lower thresholds reveal broader patterns at the cost of specificity.

In practice, NØMAD achieves zero-infrastructure deployment through a single SQLite database with no external services required. The system provides system-level monitoring that works on any Linux machine without requiring HPC software, while optional SLURM integration enables job-level analytics and predictive alerts. The similarity network analysis learns failure patterns directly from historical data, adapting to site-specific workload characteristics. Beyond operational monitoring, an educational analytics module tracks the development of computational proficiency over time, enabling instructors to generate insights on students efficiency in using HPC resources.''

\subsection*{Implementation and Architecture}
NØMAD is implemented in Python and follows a modular architecture with seven main components (Figure~\ref{fig:architecture}):

\begin{figure}[htbp]
\centering
\includegraphics[width=0.9\textwidth]{figures/architecture.png}
\caption{NØMAD system architecture showing the data flow from collectors through the analysis engines to the alert dispatcher and web dashboard. The monitoring engine handles threshold-based alerts while the prediction engine uses ML models for proactive failure detection.}
\label{fig:architecture}
\end{figure}

\textbf{Collectors} form the foundation of the system, gathering metrics via systemd timers at configurable intervals (default: 60 seconds). They pull data from standard Linux tools---\texttt{iostat}, \texttt{vmstat}, \texttt{nvidia-smi}, and \texttt{nfsiostat}---along with filesystem utilities. When SLURM is available, additional collectors capture queue state, job history, and per-job I/O statistics from \texttt{/proc/[pid]/io}. Importantly, collectors degrade gracefully when their requirements are not met: a system without GPUs simply skips GPU monitoring rather than failing.

Raw metrics then flow through \textbf{Feature Engineering}, which transforms them into a standardized feature vector for each job. System-level features capture I/O wait, memory pressure, swap activity, and device utilization. With SLURM integration, job-specific features---CPU and memory efficiency, NFS write ratios, runtime characteristics---extend the vector to 17 dimensions, enabling meaningful similarity comparisons across jobs.

These features feed into the \textbf{ML Prediction} engine, which employs an ensemble of three complementary models: a Graph Neural Network (GNN) that captures relationships between similar jobs, an LSTM that detects temporal patterns and early warning trajectories, and an Autoencoder that identifies anomalous jobs deviating from learned normal behavior. Rather than producing binary classifications, the ensemble outputs a continuous risk score between 0 and 1, allowing administrators to set thresholds based on their operational needs.

The \textbf{Alert System} acts on both threshold-based triggers (such as disk usage or GPU temperature) and predictive signals from the ML engine. A key capability is derivative analysis: when the rate of change indicates an impending threshold breach, alerts fire proactively rather than reactively. Notifications route through email, Slack, or webhooks, with configurable cooldowns to prevent alert fatigue.

Before ML models can provide reliable predictions, sufficient training data must be collected. The \textbf{Data Readiness Estimator} addresses this bootstrap problem by assessing sample size adequacy, class balance between successful and failed jobs, feature coverage and variance, and data recency. Based on current collection rates, it forecasts time-to-readiness---for example, ``At 125 jobs/day, recommended threshold will be reached in approximately 3 days.'' The \texttt{nomad readiness} command produces detailed reports with actionable recommendations.

For troubleshooting, the \textbf{Diagnostics Module} provides targeted analysis through \texttt{nomad diag} commands that examine network performance between nodes, storage health and I/O patterns, or node-level resource bottlenecks. Each diagnostic produces both summary statistics and detailed breakdowns, accelerating root cause identification.

Finally, \textbf{Infrastructure Monitoring} extends visibility beyond compute nodes to encompass the broader research environment. The dashboard includes dedicated views for departmental workstations---tracking CPU, memory, disk usage, and logged-in users---as well as storage servers with ZFS pool health, NFS client connections, and I/O metrics. This holistic perspective enables administrators to correlate job failures with infrastructure-wide issues such as NFS server congestion or storage capacity constraints.
\subsection*{Web Dashboard}
NØMAD provides a real-time web dashboard for monitoring cluster health and job status (Figure~\ref{fig:dashboard}). The dashboard displays partition-specific metrics including queue depth, node utilization, and resource consumption patterns.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.95\textwidth]{figures/dashboard.png}
\caption{NØMAD web dashboard in light theme showing real-time cluster status. The main view displays three partitions (compute, highmem, gpu) with node health rings indicating CPU utilization. The sidebar shows detailed statistics for the selected node including job counts, resource utilization, and top users.}
\label{fig:dashboard}
\end{figure}

The dashboard provides additional analytics views for resource tracking and infrastructure monitoring. The usage analytics view (Figure~\ref{fig:usage}) shows CPU and GPU usage by group and user, plus job submission patterns as a heatmap. Interactive computing sessions (Figure~\ref{fig:interactive}) display active RStudio and Jupyter sessions. The infrastructure monitoring view (Figure~\ref{fig:infrastructure}) extends visibility to departmental workstations and storage servers.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.85\textwidth]{figures/usage-analytics.png}
\caption{Usage analytics views. \textbf{Top}: Resource usage summary showing CPU-hours, GPU-hours, and breakdown by group and user. \textbf{Bottom}: Activity heatmap displaying job submissions by day and hour, revealing usage patterns.}
\label{fig:usage}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.85\textwidth]{figures/interactive-sessions.png}
\caption{Interactive computing sessions dashboard showing active RStudio and Jupyter sessions with memory usage, session age, and status.}
\label{fig:interactive}
\end{figure}
\begin{figure}[htbp]
\centering
\includegraphics[width=0.85\textwidth]{figures/infrastructure.png}
\caption{Infrastructure monitoring views. \textbf{Top}: Workstation overview showing departmental machines (Biology, Chemistry, Physics, Math/CS) with status, CPU load, memory, disk usage, and logged-in users. \textbf{Bottom}: Storage overview displaying NFS servers with capacity, usage, ZFS pool health, and connected clients.}
\label{fig:infrastructure}
\end{figure}
\subsection*{Job Similarity Network}
A distinguishing feature of NØMAD is the job similarity network visualization (Figure~\ref{fig:network}). Jobs are represented as nodes in a 3D space defined by their I/O characteristics: NFS write ratio, local write volume, and I/O wait percentage. When full job metrics are available, edges connect jobs with cosine similarity $\geq 0.7$ based on their feature vectors.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.8\textwidth]{figures/network.png}
\caption{Job similarity network visualization with feature variance analysis. The 3D view shows jobs colored by outcome (green=completed, red=failed, orange=timeout, purple=OOM). The left panel displays feature variance statistics sorted by coefficient of variation (CV); high CV values for exit\_signal and failure\_reason (exceeding 200\%) reflect normal cluster operation where most jobs succeed. The legend shows job outcome distribution across 1000 jobs.}
\label{fig:network}
\end{figure}

The feature variance panel helps administrators verify normal cluster operation and identify which metrics contribute most to failure prediction.
\subsection*{Quality Control}
NØMAD includes a comprehensive test suite that ensures reliability across all components. Unit tests cover collectors, feature engineering, and ML components individually, while integration tests verify the full data pipeline from metric collection through prediction. For evaluation without a production cluster, a demo mode (\texttt{nomad demo}) generates synthetic HPC data with realistic patterns. Continuous integration via GitHub Actions runs the test suite on every commit.

The software has been tested on clusters ranging from 6 to 200 nodes, including both CPU-only and GPU-enabled partitions. The codebase follows PEP 8 style guidelines and includes type hints for improved maintainability.
\subsection*{Educational Analytics}

NØMAD includes an educational analytics module (\texttt{nomad edu}) designed for classroom instruction, research mentorship, and HPC training programs. The module tracks the development of computational proficiency over time by analyzing per-job behavioral fingerprints across five dimensions: CPU efficiency, memory sizing, time estimation, I/O awareness, and GPU utilization.

The \textbf{Job Explanation} feature (\texttt{nomad edu explain}) translates raw job data into plain-language feedback that students can immediately act upon. For each completed job, the system provides dimension-specific scores (0--100), proficiency levels (Excellent, Good, Developing, Needs Work), and actionable recommendations. For example, a job with 21\% CPU utilization receives the feedback: ``Very low CPU utilization---requested 4 cores but used $\sim$1. Try: \texttt{\#SBATCH --ntasks=1}.''

\begin{figure}[htbp]
\centering
\includegraphics[width=0.45\textwidth]{figures/edu_explain.png}\hspace{0.5cm}\includegraphics[width=0.45\textwidth]{figures/edu_trajectory.png}

\vspace{0.3cm}

\includegraphics[width=0.45\textwidth]{figures/edu_report.png}

\vspace{0.2cm}


\caption{Educational analytics outputs. \textbf{Top left} (\texttt{nomad edu explain 1104}): Job explanation
with proficiency scores and recommendations. \textbf{Top right} (\texttt{nomad edu trajectory alice}): User trajectory
tracking improvement over 173 jobs. \textbf{Bottom} (\texttt{nomad edu report cs101}): Group report for a course
section with per-student breakdown.}
\label{fig:edu}
\end{figure}

Beyond individual job feedback, \textbf{User Trajectories} (\texttt{nomad edu trajectory}) track each person's improvement across their job submissions. The system computes sliding-window averages to identify trends---improving, stable, or declining---for each proficiency dimension, enabling mentors to provide targeted guidance where it is most needed.

At the class level, \textbf{Group Reports} (\texttt{nomad edu report}) aggregate proficiency data across course sections or research groups. Instructors can generate summaries such as ``15 of 20 students improved memory efficiency over the semester'' or identify that a majority of students struggle with I/O patterns, suggesting curriculum adjustments.
These features address a common challenge in HPC education: students submit
jobs that technically complete but exhibit significant resource waste or
suboptimal patterns. Traditional approaches require manual inspection of
\texttt{sacct} output, which is impractical for classes with hundreds of
students. NØMAD automates this assessment while providing pedagogically useful
feedback that helps students develop genuine computational proficiency rather
than simply learning to avoid errors.

Proficiency scores are persisted to the database, enabling longitudinal studies
of HPC training effectiveness and research into factors that accelerate skill
development.

\section*{(2) Availability}

\subsection*{Operating System}
Linux (tested on Ubuntu 22.04, Rocky Linux 9, CentOS 7)

\subsection*{Programming Language}
Python 3.9+

\subsection*{Additional System Requirements}
\begin{itemize}
\item SLURM workload manager (optional, enables job-level analytics)
\item sysstat package (\texttt{iostat}, \texttt{mpstat}) for system metrics
\item Network access for dashboard (default port 5000)
\item Minimal disk space for SQLite database ($\sim$1MB per 10,000 samples)
\end{itemize}

\subsection*{Dependencies}
\begin{itemize}
\item click $\geq$ 8.0
\item toml $\geq$ 0.10
\item numpy $\geq$ 1.21
\item pandas $\geq$ 1.3
\item scipy $\geq$ 1.7
\item scikit-learn \cite{sklearn} (optional, for ML features)
\item torch (optional, for GNN/LSTM models)
\item torch-geometric (optional, for graph neural networks)
\end{itemize}

\subsection*{List of Contributors}
\begin{enumerate}
\item Tonini, João Filipe Riva (Lead developer)
\end{enumerate}

\subsection*{Software Location}

\subsubsection*{Archive}
\begin{tabular}{ll}
Name: & Zenodo \\
Persistent identifier: & \url{https://doi.org/10.5281/zenodo.18614517} \\
Licence: & AGPL-3.0-or-later \\
Publisher: & João Filipe Riva Tonini \\
Version: & 1.2.2 \\
Date published: & February 2026 \\
\end{tabular}

\subsubsection*{Code Repository}
\begin{tabular}{ll}
Name: & GitHub \\
Identifier: & \url{https://github.com/jtonini/nomad-hpc} \\
Licence: & AGPL-3.0-or-later \\
Date published: & December 2025 \\
\end{tabular}
\subsubsection*{Package Repository}
\begin{tabular}{ll}
Name: & PyPI \\
Identifier: & \url{https://pypi.org/project/nomad-hpc/} \\
Installation: & \texttt{pip install nomad-hpc} \\
\end{tabular}

\subsubsection*{Project Website}
\begin{tabular}{ll}
URL: & \url{https://nomad-hpc.com} \\
Documentation: & \url{https://jtonini.github.io/nomad-hpc/} \\
\end{tabular}
\subsection*{Language}
English

\section*{(3) Reuse Potential}

NØMAD is designed for broad reuse across HPC environments of varying scales. The software can be deployed in several contexts:

\textbf{Small Research Groups}: Groups managing individual workstations or small clusters can use NØMAD's zero-infrastructure design to implement sophisticated monitoring without enterprise tools. The \texttt{nomad demo} mode allows evaluation without requiring existing HPC infrastructure.

\textbf{Medium HPC Centers}: University and institutional HPC centers can deploy NØMAD as either a primary monitoring solution or as a complement to existing tools like Grafana or Nagios, adding predictive capabilities to traditional threshold-based alerting.

\textbf{Research Applications}: The similarity network approach provides a
framework for studying HPC failure patterns. The network structure, combined
with job-level proficiency scores, enables quantitative analysis of resource
usage patterns and their relationship to job outcomes.

\textbf{Community Data Sharing}: The \texttt{nomad community export} command
generates anonymized datasets suitable for cross-institutional research. Export
formats include:
\begin{itemize}
\item \textbf{Job fingerprints}: Feature vectors with hashed user/job identifiers
\item \textbf{Failure patterns}: Aggregated statistics on failure modes by resource profile
\item \textbf{Proficiency distributions}: Anonymized skill development trajectories
\end{itemize}
These exports enable collaborative research on HPC usage patterns without
exposing sensitive institutional data. Researchers can study questions such as:
Which failure modes are universal vs.\ site-specific? Do proficiency
improvement rates vary by discipline? What resource configurations correlate
with job success across different cluster architectures?

The anonymization process removes usernames, job names, and absolute timestamps
while preserving the relational structure needed for network-based analysis.
Exported data uses relative time offsets and hashed identifiers, making it
suitable for publication as supplementary materials or inclusion in shared
research datasets.

\textbf{Educational Use}: Beyond the demo mode, NØMAD provides a complete
educational analytics pipeline. Instructors can assign Linux groups to course
sections (e.g., \texttt{cs101}, \texttt{bio301}) and use \texttt{nomad edu
report} to track class-wide proficiency development. Individual students
receive automated feedback via \texttt{nomad edu explain}, reducing instructor
workload while providing immediate, actionable guidance. The module is
particularly valuable for:
\begin{itemize}
\item \textbf{HPC workshops}: Pre/post assessment of participant skills
\item \textbf{Research onboarding}: Tracking new graduate students' development
\item \textbf{Classroom instruction}: Automated grading of computational assignments
\item \textbf{Self-directed learning}: Students can independently review their job history
\end{itemize}

\subsection*{Extension Points}
Developers can extend NØMAD in several ways:
\begin{itemize}
\item \textbf{Custom Collectors}: Add new metric sources by implementing the collector interface
\item \textbf{Alert Channels}: Integrate additional notification services beyond email/Slack/webhooks
\item \textbf{ML Models}: Train site-specific models using the provided feature engineering pipeline
\item \textbf{Dashboard Widgets}: Extend the web dashboard with custom visualizations
\end{itemize}

\subsection*{Support}
\begin{itemize}
\item GitHub Issues: \url{https://github.com/jtonini/nomad-hpc/issues}
\item Email: jtonini@richmond.edu
\item Documentation: \url{https://jtonini.github.io/nomad-hpc/}
\end{itemize}

Users and developers are welcome to submit bug reports, feature requests, and pull requests via GitHub.

\section*{Acknowledgements}
The author thanks George Flanagin for advice and inspiration on HPC system administration, and the University of Richmond's Office of the Provost for financial and resource support.

\section*{Funding Statement}
This work was supported by the University of Richmond.

\section*{Competing Interests}
The author declares no competing interests.

\begin{thebibliography}{10}

\bibitem{slurm}
Yoo, A.B., Jette, M.A., Grondona, M. (2003). SLURM: Simple Linux Utility for Resource Management. In: Job Scheduling Strategies for Parallel Processing, Lecture Notes in Computer Science, vol. 2862, Springer, pp. 44--60. DOI: \url{https://doi.org/10.1007/10968987_3}

\bibitem{prometheus}
Prometheus Authors (2012--present). Prometheus: From metrics to insight.
URL: \url{https://prometheus.io/}

\bibitem{grafana}
Grafana Labs (2014--present). Grafana: The open observability platform.
URL: \url{https://grafana.com/}

\bibitem{nagios}
Galstad, E. (1999--present). Nagios: The industry standard in IT
infrastructure monitoring. URL: \url{https://www.nagios.org/}

\bibitem{tacc}
Evans, R.T., Browne, J.C., Barth, W.L. (2014). Comprehensive resource use monitoring for HPC systems with TACC Stats. In: Proceedings of the First International Workshop on HPC User Support Tools, IEEE, pp. 13--21. DOI: \url{https://doi.org/10.1109/SC.2014.18}

\bibitem{xdmod}
Palmer, J.T., Gallo, S.M., Furlani, T.R., Jones, M.D., DeLeon, R.L., White, J.P., Simakov, N., Patra, A.K., Sperhac, J., Yearke, T., Rathsam, R., Inber, M., Guillen, O., Cornelius, C.D. (2015). Open XDMoD: A tool for the comprehensive management of high-performance computing resources. Computing in Science \& Engineering 17(4):52--62. DOI: \url{https://doi.org/10.1109/MCSE.2015.32}

\bibitem{ldms}
Agelastos, A., Allan, B., Brandt, J., Cassella, P., Enos, J., Fullop, J., Gentile, A., Monk, S., Naksinehaboon, N., Ogden, J., Rajan, M., Showerman, M., Stevenson, J., Taerat, N., Tucker, T. (2014). The Lightweight Distributed Metric Service: A scalable infrastructure for continuous monitoring of large scale computing systems and applications. In: Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis, IEEE, pp. 154--165. DOI: \url{https://doi.org/10.1145/2616498.2616533}

\bibitem{mlhpc}
Tuncer, O., Ates, E., Zhang, Y., Turber, A., Brandt, J., Leung, V.J.,
Egele, M., Coskun, A.K. (2017). Diagnosing performance variations in HPC
applications using machine learning. In: High Performance Computing,
Lecture Notes in Computer Science, vol. 10266, Springer, pp. 355--373.
DOI: \url{https://doi.org/10.1007/978-3-319-58667-0_19}

\bibitem{vilhena}
Vilhena, D.A., Antonelli, A. (2015). A network approach for identifying
and delimiting biogeographical regions. Nature Communications 6:6848.
DOI: \url{https://doi.org/10.1038/ncomms7848}

\bibitem{sklearn}
Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J., Passos, A., Cournapeau, D., Brucher, M., Perrot, M., Duchesnay, E. (2011). Scikit-learn: Machine learning in Python. Journal of Machine Learning Research 12:2825--2830. URL: \url{http://jmlr.org/papers/v12/pedregosa11a.html}

\end{thebibliography}

\end{document}
